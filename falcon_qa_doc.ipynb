{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from typing import Dict, List\n",
    "\n",
    "import boto3\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us-west-2\n"
     ]
    }
   ],
   "source": [
    "aws_region = boto3.Session().region_name\n",
    "print(aws_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Falcon-7b-instruct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandlerLLM(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({'inputs': prompt, 'parameters': model_kwargs})\n",
    "        return input_str.encode('utf-8')\n",
    "      \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))        \n",
    "        return response_json[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"falcon-7b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\": 300,\n",
    "    \"return_full_text\": False,\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.3,\n",
    "}\n",
    "\n",
    "content_handler = ContentHandlerLLM()\n",
    "\n",
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    region_name=aws_region,\n",
    "    model_kwargs=parameters,\n",
    "    content_handler=content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' on Earth?\\nThe largest mammal on Earth is the blue whale.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"What is the largest mammal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SagemakerEndpointEmbeddingsJumpStart` [Source](https://medium.com/@ryanntk/deploying-hugging-face-embedding-models-on-aws-sagemaker-a-comprehensive-tutorial-with-langchain-af8e0b405b51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# extend the SagemakerEndpointEmbeddings class from langchain to provide a custom embedding function\n",
    "class SagemakerEndpointEmbeddingsJumpStart(SagemakerEndpointEmbeddings):\n",
    "    def embed_documents(\n",
    "        self, texts: List[str], chunk_size: int = 5\n",
    "    ) -> List[List[float]]:\n",
    "        \"\"\"Compute doc embeddings using a SageMaker Inference Endpoint.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "            chunk_size: The chunk size defines how many input texts will\n",
    "                be grouped together as request. If None, will use the\n",
    "                chunk size specified by the class.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        _chunk_size = len(texts) if chunk_size > len(texts) else chunk_size\n",
    "        st = time.time()\n",
    "        for i in range(0, len(texts), _chunk_size):\n",
    "            response = self._embedding_func(texts[i : i + _chunk_size])\n",
    "            results.extend(response)\n",
    "        time_taken = time.time() - st\n",
    "        print(\n",
    "            f\"got results for {len(texts)} in {time_taken}s, length of embeddings list is {len(results)}\"\n",
    "        )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        \"\"\"\n",
    "        Transforms the input into bytes that can be consumed by SageMaker endpoint.\n",
    "        Args:\n",
    "            inputs: List of input strings.\n",
    "            model_kwargs: Additional keyword arguments to be passed to the endpoint.\n",
    "        Returns:\n",
    "            The transformed bytes input.\n",
    "        \"\"\"\n",
    "        # Example: inference.py expects a JSON string with a \"inputs\" key:\n",
    "        # input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        input_str = json.dumps({\"inputs\": inputs, \"parameters\": model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Transforms the bytes output from the endpoint into a list of embeddings.\n",
    "        Args:\n",
    "            output: The bytes output from SageMaker endpoint.\n",
    "        Returns:\n",
    "            The transformed output - list of embeddings\n",
    "        Note:\n",
    "            The length of the outer list is the number of input strings.\n",
    "            The length of the inner lists is the embedding dimension.\n",
    "        \"\"\"\n",
    "        # Example: inference.py returns a JSON string with the list of\n",
    "        # embeddings in a \"vectors\" key:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"vectors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "emb_parameters = {\"device\": \"cuda\"}\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddingsJumpStart(\n",
    "    # credentials_profile_name=\"credentials-profile-name\",\n",
    "    endpoint_name=\"sentence-transformers-all-mpnet-base-v2\",\n",
    "    region_name=aws_region,\n",
    "    content_handler=content_handler,\n",
    "    model_kwargs=emb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"foo bar dog\")\n",
    "len(query_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got results for 2 in 0.7462847232818604s, length of embeddings list is 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_documents([\"foo bar dog\", \"Veronica is a Pythonista\"])\n",
    "len(query_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.023010829463601112, 0.06674211472272873, 0.015658535063266754, -0.059901751577854156, 0.00899288710206747, 0.04786750301718712, 0.005673463921993971, 0.023586349561810493, -0.06605415046215057, 0.02126981131732464, -0.0002889889001380652, 0.03975634276866913, -0.03429273143410683, 0.05184069275856018, 0.02275446429848671, -0.01708190329372883, 0.017952624708414078, 0.03652235493063927, 0.07056411355733871, -0.040407828986644745, -0.00187441217713058, 0.02352127991616726, 0.004665896762162447, 0.018560048192739487, -0.047574300318956375, 0.002585913985967636, -0.018474262207746506, -0.003118740627542138, -0.06551744788885117, -0.013685131445527077, -0.04172193631529808, 0.01329813152551651, -0.017570368945598602, 0.003636210458353162, 2.1068485693831462e-06, -0.01581939496099949, -0.01604585535824299, 0.005425119306892157, 0.0680365040898323, -0.05921432375907898, -0.08718516677618027, -0.020225796848535538, -0.02191966399550438, 0.006423304323107004, -0.029958896338939667, -0.06446627527475357, 0.027559543028473854, 0.05543999373912811, -0.028078239411115646, 0.05419043079018593, 0.0026187326293438673, -0.06932499259710312, -0.04494498670101166, -0.006852503400295973, 0.06747487187385559, -0.030603639781475067, -0.015401860699057579, 0.03245040401816368, -0.02740316651761532, 0.01179177314043045, -0.004053470212966204, -0.01009947806596756, 0.0403747633099556, -0.01324413251131773, -0.02347446233034134, 0.03465811908245087, -0.07925324887037277, 0.04883779212832451, -0.01725759170949459, 0.018148820847272873, -0.028094980865716934, -0.03544998541474342, -0.017630720511078835, 0.06869210302829742, 0.03419966250658035, -0.06409057974815369, -0.0016255058581009507, 0.014894452877342701, 0.04303397610783577, 0.016619134694337845, -0.0655159205198288, -0.026041580364108086, 0.011132064275443554, 0.02523624338209629, -0.039060771465301514, 0.06385379284620285, -0.02139345556497574, -0.007874553091824055, 0.005833492614328861, 0.05675233528017998, -0.010215059854090214, 0.015196838416159153, 0.023410920053720474, 0.049527719616889954, -0.01400525402277708, 0.007330155000090599, -0.027285123243927956, 0.006774749141186476, -0.009495573118329048, 0.03008597530424595, 0.006717353127896786, 0.0014923124108463526, 0.00787079893052578, 0.04534438997507095, 0.0031724045984447002, 0.02922164462506771, -0.01954904943704605, -0.029319165274500847, 0.02546115778386593, -0.05150489881634712, -0.07623180747032166, -0.009595748037099838, -0.010187103413045406, 0.0419883131980896, 0.03391626849770546, -0.02373092621564865, 0.0013637612573802471, 0.022877639159560204, 0.00831610057502985, 0.010663634166121483, -0.013551000505685806, -0.011806602589786053, 0.02341092750430107, 0.07065224647521973, 0.04271245747804642, 0.005824619438499212, -0.10125032067298889, 0.054022956639528275, 0.006044263485819101, 0.01107492670416832, 0.007341252639889717, 0.03353413566946983, -0.06093713268637657, -0.027571193873882294, 0.016989216208457947, -0.005499851889908314, -0.0069758277386426926, -0.01142292283475399, -0.0018827557796612382, -0.012339175678789616, -0.07685516774654388, -0.04822944477200508, 0.004893387667834759, -0.04497228562831879, 0.007427186705172062, -0.031675372272729874, -0.0013049524277448654, 0.03579952195286751, -0.03668150305747986, -0.013009931892156601, 0.015499680303037167, 0.007876859977841377, -0.08967886120080948, -0.010298510082066059, -0.00795599166303873, 0.02673277072608471, -0.057854581624269485, -0.03302031382918358, 0.010414022020995617, 0.0010603995760902762, 0.005370123777538538, 0.002366454340517521, -0.044107601046562195, -0.013039017096161842, 0.003458276391029358, -0.03264845535159111, -0.010508754290640354, -0.00835302472114563, 0.004713899921625853, -0.04510847106575966, -0.012755651958286762, 0.01692296750843525, 0.030524250119924545, 0.03768853098154068, 0.035064708441495895, 0.05048993602395058, 0.02682623639702797, 0.017809994518756866, -0.030583703890442848, -0.04651307314634323, 0.030226953327655792, -0.03472358360886574, 0.014279928989708424, 0.001994319027289748, -0.07616851478815079, -0.021231915801763535, 0.041119519621133804, 0.023551054298877716, -0.02902073785662651, -0.02129901573061943, 0.0398409366607666, 0.004537781234830618, 0.023622728884220123, 0.03720119595527649, 0.015066093765199184, 0.014487423934042454, 0.0025482350029051304, -0.1087401732802391, 0.005506589543074369, 0.020443687215447426, -0.05446306988596916, 0.048238396644592285, 0.026937145739793777, -0.0003474353579804301, 0.011624503880739212, 0.020883390679955482, 0.06968170404434204, -0.021589716896414757, 0.009883466176688671, 0.013504407368600368, 0.007010550703853369, -0.005145477131009102, 0.01859726570546627, 0.06254380941390991, -0.008416026830673218, 0.051103487610816956, 0.012462976388633251, -0.0014173596864566207, 0.049751847982406616, 0.06316088140010834, -0.01048077642917633, 0.04253240302205086, -0.019946375861763954, 0.01848849654197693, 0.10847096145153046, -0.031477123498916626, 0.0014083576388657093, -0.017507240176200867, 0.045508984476327896, 0.005288006272166967, -0.01992693357169628, -0.012253225781023502, 0.05077618733048439, 0.031070396304130554, 0.03807516768574715, -0.01251057256013155, 0.0337238647043705, -0.004974474664777517, 0.010957763530313969, 0.03183368593454361, 0.020739996805787086, 0.03824857249855995, -0.007297822739928961, 0.0013917008182033896, 0.07464830577373505, 0.007142022717744112, 0.08202540874481201, -0.008178972639143467, -0.003124932525679469, -0.019090555608272552, -0.022937530651688576, -0.026072589680552483, -0.004665476270020008, -0.02244298905134201, 0.03574899211525917, -0.0337204672396183, 0.0674581378698349, 0.004455369897186756, -0.0013021505437791348, -0.021021761000156403, 0.1279732584953308, -0.006083676125854254, 0.0007607946172356606, 0.038103315979242325, 0.015111555345356464, -0.0037356307730078697, -0.028185483068227768, -0.03302307426929474, -0.012463519349694252, -0.011571018025279045, 0.04976337403059006, 0.019924204796552658, -0.004556228872388601, 0.022879982367157936, -0.05274885147809982, -0.019249511882662773, 0.00212375121191144, -0.045621905475854874, -0.010462688282132149, -0.0036699266638606787, 0.03641803190112114, 0.034517351537942886, 0.01942635513842106, 0.02007974684238434, -0.01511363685131073, -0.0463373176753521, -0.012162714265286922, 0.0020720127504318953, -0.03927887603640556, -0.020818596705794334, -0.042365141212940216, -0.018530000001192093, 0.03966914862394333, -0.017651056870818138, 0.025569723919034004, 0.03735378757119179, 0.02802629955112934, -0.05534663423895836, 0.024187644943594933, 0.015183375217020512, 0.03360293060541153, 0.04908657446503639, 0.008308899588882923, -0.025269975885748863, 0.016446353867650032, -0.007383799646049738, -0.039706017822027206, 0.024582283571362495, 0.03308204934000969, -0.03622559458017349, 0.043494582176208496, 0.0015286939451470971, -0.028200285509228706, 0.0863780602812767, 0.014692171476781368, -0.05767326056957245, -0.05677102878689766, -0.055296946316957474, -0.02605327032506466, 0.012740252539515495, 0.02138972096145153, 0.005055899266153574, 2.5503759388811886e-05, -0.019994748756289482, -0.010931555181741714, 0.03636316582560539, -0.055819783359766006, 0.01594778522849083, 0.05470077320933342, -0.010836183093488216, 0.023871170356869698, 0.08289739489555359, 0.005749847274273634, -0.02573838084936142, 0.011421150527894497, -0.04512236267328262, -0.011098035611212254, -0.06551823765039444, 0.007781904190778732, 0.03390177711844444, 0.027678584679961205, 0.008255341090261936, -0.014465789310634136, -0.03405260294675827, -0.04136351868510246, 0.015928974375128746, -0.13232514262199402, -0.014237525872886181, -0.04330163449048996, -0.03351152688264847, -0.004496952053159475, -0.031220128759741783, 0.010743004269897938, -0.02696734480559826, 0.0033131353557109833, 0.037518925964832306, 0.023038649931550026, -0.019067568704485893, 0.007505213841795921, 0.026823237538337708, -0.08967205137014389, 0.0011069491738453507, 0.05954236164689064, -0.004369743168354034, -0.033817000687122345, 0.038619786500930786, 0.013515312224626541, 0.0023591218050569296, -0.013474767096340656, 0.015064521692693233, -0.035000432282686234, -0.007012957241386175, 0.020978230983018875, 0.08536477386951447, -0.007563481107354164, 0.06456395983695984, 0.04707031697034836, 0.018174339085817337, 0.045861173421144485, -0.027728598564863205, 0.06230560690164566, -0.09495425969362259, -0.024466896429657936, 0.004062929656356573, -0.020227771252393723, -0.007179840002208948, 0.051411114633083344, -0.02549796737730503, -0.05659577623009682, 0.01716974750161171, 0.033926818519830704, -0.04299122467637062, -0.05843474343419075, 0.0066446540877223015, -0.00794366654008627, -0.012367756105959415, -0.05391916632652283, -0.00024091439263429493, -0.003016125177964568, 0.020995721220970154, -0.020286129787564278, 0.14206643402576447, 0.025578737258911133, 0.02990243397653103, 0.004624832887202501, 0.008555535227060318, 0.07362736761569977, -0.007198780309408903, 0.0008469286258332431, 0.049492139369249344, -0.034237056970596313, -0.10526195168495178, 0.017486561089754105, -0.013994946144521236, -0.03264278545975685, -0.033486008644104004, 0.012874714098870754, -0.019406288862228394, -0.02978390082716942, -0.03531445935368538, 0.031493593007326126, -0.02057923749089241, -0.02754892036318779, -0.01977190561592579, -0.055223383009433746, -0.00915698241442442, 0.031369246542453766, 5.041166514274664e-05, 0.06581266224384308, 0.005811075679957867, 0.004947269801050425, -0.010235033929347992, -0.006612847093492746, -0.0666307583451271, 0.03872339800000191, -0.07772387564182281, -0.010483360849320889, -0.0407271534204483, -0.08086185902357101, -0.042168840765953064, -0.02000986412167549, 0.0040548089891672134, -0.020952513441443443, -0.044977884739637375, 0.06145330145955086, -0.09113430976867676, -0.004462599754333496, 0.022423872724175453, 0.03445257991552353, -0.006614299025386572, 0.008550687693059444, -0.061580006033182144, -0.053340718150138855, -0.017241502180695534, 0.08175063878297806, -0.011567949317395687, 0.03487201780080795, 0.06383499503135681, -0.01461495365947485, 0.019816551357507706, 0.07007011026144028, 0.023461509495973587, 0.0015498349675908685, -0.039492007344961166, 0.061980392783880234, -0.006202668882906437, -0.0521758496761322, -0.0032829332631081343, 0.022535966709256172, -0.01106068305671215, -0.06306261569261551, 0.009892704896628857, -0.018681492656469345, 0.0032396765891462564, 0.023204542696475983, -0.009349946863949299, 0.005748561583459377, -0.11012148857116699, -0.0627870112657547, 0.024547163397073746, 0.01729448325932026, -0.025977447628974915, -0.014056234620511532, -0.05644175410270691, 0.011549227871000767, 0.019201824441552162, 0.003449459793046117, -0.01110924407839775, -0.02803686633706093, -0.05116214603185654, -0.0037593026645481586, -0.022287728264927864, -0.009074483998119831, -0.04227137938141823, -0.020952653139829636, 0.023293308913707733, -0.07390297949314117, -0.03696122020483017, 0.012173552997410297, 0.006799119058996439, 0.015167376957833767, 0.004703959915786982, -0.0008468967862427235, 0.06477215886116028, -0.0013019004836678505, 0.01633444055914879, -0.006077290046960115, -0.00752828735858202, -0.012115146033465862, -0.04492707550525665, 0.004496962297707796, -0.002900796476751566, -0.0778275653719902, -0.01946399360895157, 0.004633028991520405, -0.016914010047912598, -0.02397526241838932, -0.0216082651168108, 0.01028000470250845, -0.013051548041403294, -0.0007539827493019402, -0.02092389203608036, 0.008950836956501007, -0.017262734472751617, 0.018538203090429306, -0.05445658415555954, 0.016340481117367744, -0.0012404675362631679, 0.019093187525868416, 0.04756149277091026, 0.04087996110320091, 0.03385937213897705, 0.01503147091716528, 0.02589898183941841, 0.004808834753930569, 0.03551849350333214, 0.08423428982496262, 0.07739220559597015, -0.028364337980747223, 0.03009629249572754, -0.007325999438762665, 0.002759980270639062, -0.011097123846411705, -0.03555351123213768, 0.07339684665203094, 0.04047708213329315, 0.027645396068692207, 0.057102106511592865, -0.03865982964634895, 0.03840562701225281, -0.021623192355036736, 0.0070581817999482155, 0.025119509547948837, -0.02347157895565033, -0.07514849305152893, -7.569902970019273e-33, -0.01588786207139492, -0.061238691210746765, 0.020396197214722633, -0.003003151388838887, -0.09604564309120178, -0.0395798534154892, -0.04936326667666435, 0.0066701616160571575, -0.02741643600165844, 0.0018353798659518361, -0.039583250880241394, -0.0009279444930143654, 0.013477861881256104, -0.03961499407887459, 0.05652448907494545, -0.0036940716672688723, 0.01730922795832157, 0.01177230291068554, -0.012265512719750404, -0.02759370394051075, 0.05455484986305237, 0.029589680954813957, -0.0007720024441368878, -0.04620949551463127, -0.029540466144680977, 0.05297929793596268, -0.07141607999801636, -0.04870860278606415, 0.03284231945872307, -0.014889433048665524, 0.02743079699575901, 0.0251883864402771, 0.011688550002872944, 0.04583723470568657, -0.009786230511963367, -0.022422121837735176, -0.037831224501132965, 0.005389497149735689, 0.04308728501200676, -0.013435769826173782, -0.00951867550611496, 0.004762003198266029, -0.032099418342113495, -0.0659119188785553, -0.014647260308265686, 0.001734729390591383, 0.014078889042139053, -0.03751515969634056, 0.005206228233873844, -0.040992867201566696, -0.05830736458301544, -0.01646733656525612, -0.027035633102059364, -0.02279207855463028, -0.002234056359156966, 0.030421718955039978, -0.013256027363240719, 0.005003741942346096, 0.03847838193178177, 0.01069438923150301, 0.04410755634307861, -0.015559962950646877, 0.013862493447959423, -0.04908732697367668, 0.023104585707187653, 0.033264875411987305, 0.04234946519136429, -0.03861241415143013, 0.029563581570982933, -0.03540949895977974, -0.009775746613740921, 0.007092204876244068, 0.019781410694122314, -0.05743137374520302, 0.05902979522943497, -0.04011101275682449, -0.017601270228624344, -0.04833642765879631, 0.08239274471998215, -0.0011447558645159006, -0.0472562238574028, 0.009285803884267807, 0.02023926191031933, 0.027294063940644264, 0.0012926597846671939, 0.03217925876379013, 0.027979955077171326, -0.04386712610721588, -0.022133518010377884, -0.00828301440924406, -0.05244899541139603, -0.026424620300531387, 0.0025984004605561495, 0.013857136480510235, 0.05617096275091171, -0.005231060553342104, -0.03087419457733631, -0.011859399266541004, 0.003875053022056818, -0.017136525362730026, 0.03928801789879799, -0.02477360889315605, 0.03139757737517357, 0.013883163221180439, 0.023625517264008522, 0.020689401775598526, 0.11114655435085297, -0.0038666129112243652, -0.011141984723508358, -0.01970728673040867, 0.011199412867426872, 0.01358599029481411, 0.031070029363036156, 0.048436325043439865, 0.034643497318029404, 0.0362677164375782, 0.004830552730709314, -0.0014726048102602363, -0.006835830397903919, 0.031388066709041595, 0.025326021015644073, 0.017306936904788017, -0.05484793707728386, 0.01671455428004265, -0.03740868717432022, 0.00724161509424448, -0.011899317614734173, 0.0361383892595768, 0.028325920924544334, 0.018300481140613556, -0.011571473442018032, 0.008201267570257187, 2.7858814632963913e-07, 0.03414873778820038, -0.016037501394748688, 0.013661477714776993, 0.07834918797016144, 0.01870156265795231, 0.0047751120291650295, -0.025973642244935036, 0.00555970286950469, -0.02857847884297371, -0.00647660531103611, 0.001415227190591395, -0.014073582366108894, 0.009553872048854828, -0.02112840674817562, 0.008032886311411858, 0.07710931450128555, -0.031797830015420914, -0.03137623146176338, 0.006319756619632244, 0.005778934340924025, -0.03378457576036453, 0.022292660549283028, 0.024898257106542587, -0.020262636244297028, -0.007175086066126823, -0.01032057125121355, -0.023920347914099693, 0.029783012345433235, 0.05430519953370094, -0.043410759419202805, -0.06804252415895462, 0.05560963600873947, -0.02781541831791401, -0.03115813061594963, -0.026592452079057693, -0.02775963582098484, -0.023671235889196396, 0.04942530766129494, 0.015187922865152359, 0.03165620192885399, -0.030071092769503593, 0.013661907985806465, -0.010235030204057693, 0.04684643819928169, 0.03315334394574165, -0.010108760558068752, -0.0008697279845364392, 0.06759144365787506, -0.04992649704217911, -0.02201100066304207, -0.00654872041195631, -0.05754455178976059, 0.02960176207125187, 0.017233718186616898, 0.00449666753411293, -0.0016306889010593295, 0.05527477711439133, 0.00944055151194334, -0.007946529425680637, 0.0017343375366181135, 0.015063010156154633, 0.012958833947777748, 0.010433575138449669, 0.012985926121473312, -0.01247435063123703, -0.1099582090973854, -0.02212277054786682, 2.022774148505684e-34, 0.0023825266398489475, 0.006947158370167017, 0.039792224764823914, 0.055848535150289536, -0.03635522723197937, 0.013340016826987267, -0.08889389783143997, -0.021237820386886597, 0.024268873035907745, -0.0004453130823094398, -0.0018311935709789395], [0.061259862035512924, -0.012730044312775135, 0.0026824036613106728, -0.011465274728834629, 0.05068375542759895, 0.031877122819423676, -0.05436446890234947, 0.012862945906817913, -0.0719950869679451, 0.040708523243665695, -0.05140969529747963, 0.07480666786432266, -0.0276887658983469, 0.04893019422888756, -0.04801535978913307, -0.0317375473678112, 0.00988079234957695, 0.008302600122988224, 0.08461163192987442, -0.015256528742611408, -0.02728661336004734, 0.04310128092765808, 0.01658884808421135, -0.0009410143829882145, 0.06394022703170776, -0.02336670644581318, 0.009754459373652935, 0.02499263919889927, -0.009198232553899288, 0.028949527069926262, 0.029997652396559715, -0.036026209592819214, 0.005499620456248522, 0.027064843103289604, 1.3621404377772706e-06, 0.023159587755799294, 0.0032908024732023478, 0.0027586831711232662, -0.03451159596443176, 0.0014547011815011501, -0.01853414811193943, -0.04215548560023308, 0.05172275751829147, 0.003851969027891755, -0.021167855709791183, 0.01413648296147585, 0.02666306495666504, -0.02700735069811344, 0.04513867199420929, -0.03686472773551941, 0.008840389549732208, 0.0452885664999485, -0.004341322463005781, -0.061920881271362305, 0.10748467594385147, -0.04022100940346718, -0.03185594454407692, 0.055083319544792175, 0.03458995372056961, 0.0030161680188030005, 0.04430912435054779, 0.07384045422077179, -0.014495018869638443, 0.0020232093520462513, 0.018901726230978966, -0.01021520420908928, -0.004954881966114044, -0.0577874518930912, 0.027945591136813164, 0.0024874997325241566, 0.021346237510442734, -0.04829602688550949, -0.027294596657156944, 0.0765833780169487, -0.007141354959458113, 0.04419945180416107, -0.043597590178251266, 0.01876658760011196, 0.009538955055177212, -0.0315609946846962, 0.02022865228354931, 0.026131315156817436, 0.0038307420909404755, 0.026146292686462402, -0.0451124832034111, 0.06285670399665833, 0.01700924150645733, 0.010410802438855171, -0.06277648359537125, 0.028154244646430016, 0.03492613136768341, -0.0004797727451659739, 0.029604895040392876, 0.02409542351961136, -0.0384049154818058, -0.039273492991924286, -0.019615596160292625, -0.006657628808170557, -0.03605576604604721, 0.06309423595666885, -0.0035696004051715136, 0.004051189869642258, 0.007926473394036293, 0.03019634261727333, -0.004986112006008625, 0.036801885813474655, 0.025098703801631927, 0.08525367826223373, 0.014152703806757927, -0.012752799317240715, 0.005850027780979872, -0.00394338509067893, 0.01631813868880272, -0.06480740010738373, 0.038763973861932755, -0.009271837770938873, 0.02428382635116577, 0.03931274265050888, -0.01039936114102602, 0.013874023221433163, -0.10203658789396286, 0.02869541011750698, 0.00964047946035862, 0.04541322588920593, -0.011414976790547371, 0.02381562814116478, 0.0017979562981054187, 0.028710749000310898, -0.00916791707277298, -0.03121742233633995, -0.0325828418135643, 0.008502098731696606, -0.0006144903018139303, -0.033356811851263046, 0.03322388231754303, 0.040241945534944534, 0.004760993644595146, -0.05783802270889282, 0.06828852742910385, -0.01061573252081871, 0.012471513822674751, -0.09278722107410431, 0.019242187961935997, 0.020449800416827202, 0.004211698193103075, 0.04869656264781952, 0.04665878787636757, -0.09846444427967072, 0.009791635908186436, -0.0037476876750588417, 0.018122371286153793, 0.01099429838359356, 0.023809513077139854, -0.0001606759033165872, 0.03945554420351982, 0.01640039123594761, -0.0713014230132103, -0.011260326020419598, 0.016888033598661423, 0.035192422568798065, -0.014879181981086731, -0.027346542105078697, -0.025187091901898384, -0.03161430358886719, 0.010939323343336582, 0.048018038272857666, -0.0026960994582623243, -0.012998107820749283, -0.015595328994095325, -0.014799450524151325, 0.03869382664561272, 0.02010430209338665, -0.024356519803404808, 0.013476868160068989, 0.002726753009483218, 0.0026073316112160683, -0.028035342693328857, -0.02101375162601471, 0.045001376420259476, -0.02103426679968834, 0.05342061445116997, 0.03823426365852356, -0.018225427716970444, -0.028051672503352165, -0.00895289983600378, 0.021587036550045013, -0.06964804977178574, 0.00035700423177331686, 0.006636141799390316, -0.009277825243771076, -0.006679031532257795, 0.06396621465682983, 0.027900330722332, 0.03213495761156082, -0.009875313378870487, 0.031912222504615784, -0.003118013497442007, -0.05063096433877945, -0.0127693647518754, -0.0340435653924942, -0.019848965108394623, 0.0024085980840027332, 0.041303765028715134, 0.1074737012386322, 0.0073151239193975925, -0.007012793328613043, -0.004995278548449278, -0.006549497600644827, -0.03649444133043289, 0.020564759150147438, -0.044837456196546555, 0.000322687003063038, -0.017360670492053032, 0.007923418655991554, -0.0011015684576705098, -0.03492657467722893, 0.024217311292886734, 0.03914719074964523, -0.021849066019058228, 0.012020975351333618, 0.01503303088247776, 0.06980133056640625, -0.06443732231855392, 0.026882240548729897, -0.08021458983421326, -0.0005908776074647903, -0.00607701763510704, -0.010915725491940975, -0.01296322699636221, -0.004070754628628492, -0.011647294275462627, 0.010941698215901852, 0.007760780397802591, -0.0038898708298802376, 0.0358494371175766, 0.0010955085745081306, 0.0317392498254776, -0.03358672186732292, -0.002193631837144494, -0.06086223945021629, -0.006333178374916315, 0.0928557813167572, 0.06119818240404129, 0.0009558302699588239, 0.04577077552676201, 0.039431381970644, 0.03334934264421463, -0.008732021786272526, 0.025315025821328163, 0.01605166122317314, 0.0465054027736187, 0.011868966743350029, -0.046076275408267975, 0.01560376025736332, 0.032918184995651245, 0.050018079578876495, 0.014204311184585094, -0.03069472312927246, -0.02737189270555973, -0.055995214730501175, 0.006026649847626686, 0.005982304457575083, 0.01723996363580227, -0.0369398258626461, -0.01778317429125309, 0.0093143405392766, -0.011366159655153751, 0.05078975111246109, 0.01305213663727045, -0.007943062111735344, 0.01355923805385828, 0.01226451899856329, -0.0006528773810714483, -0.02213102951645851, -0.01954868994653225, 0.014605917036533356, -0.007422484457492828, -0.03465611860156059, 0.006944101769477129, 0.004880450665950775, 0.011118220165371895, -0.027537167072296143, -0.023085618391633034, -0.010851040482521057, -0.009479071013629436, 0.07159440219402313, 0.04663970321416855, 0.028080502524971962, 0.021478498354554176, -0.04651911184191704, -0.016200341284275055, -0.031434644013643265, -0.022194568067789078, 0.025209104642271996, 0.012091556563973427, -0.002404295839369297, 0.0657775029540062, -0.0236606914550066, -0.0025592639576643705, -0.03965131193399429, 0.040602363646030426, 0.020819012075662613, 0.01960224285721779, -0.008173061534762383, -0.004717242904007435, -0.05433029681444168, 0.008864613249897957, -0.02389143593609333, -0.011330855078995228, 0.011662584729492664, -0.0560913160443306, -0.008384066633880138, 0.023387931287288666, -0.01269732415676117, 0.0513777919113636, -0.018752703443169594, -0.061474986374378204, -0.049252450466156006, 0.011808541603386402, 0.04043307527899742, 0.0489594042301178, -0.01443096250295639, -0.03535038232803345, -0.042088959366083145, 0.004382072947919369, -0.02531891129910946, -0.09835024178028107, -0.009146041236817837, 0.048755377531051636, 0.04652555659413338, 0.0056794253177940845, -0.01074307132512331, 0.017784783616662025, -0.03531479090452194, 0.016950447112321854, 0.054854877293109894, -0.01563023403286934, 0.03716464713215828, 0.005723109934478998, -0.006412619259208441, 0.007370179519057274, 0.010346941649913788, -0.06850327551364899, 0.008011112920939922, -0.057915352284908295, -0.0049882251769304276, -0.05581260472536087, -0.04295535013079643, -0.02189064957201481, -0.023088084533810616, 0.00186400196980685, 0.014880122616887093, -0.017660727724432945, 0.003284991253167391, 0.02894662693142891, 0.002734262263402343, -0.04910961911082268, -0.01884068362414837, -0.100428007543087, -0.05577238276600838, -0.03943643346428871, -0.019999220967292786, -0.05475715920329094, 0.004679710604250431, -0.0070168995298445225, 0.021061167120933533, 0.01759834587574005, 0.0020651754457503557, -0.021489284932613373, -0.028839321807026863, -0.09358783066272736, -0.049603670835494995, -0.019588645547628403, 0.002162365475669503, 0.012463229708373547, -0.027581220492720604, -0.013773342594504356, -0.024004939943552017, 0.020154306665062904, 0.009222888387739658, 0.05784578621387482, -0.06847220659255981, -0.00910986214876175, -0.008460513316094875, 0.041280750185251236, -0.00022499743499793112, 0.01957433484494686, -0.06597936153411865, 0.02598203346133232, -0.022144416347146034, -0.0008158613927662373, -0.013945568352937698, -0.01477131713181734, 0.016565384343266487, 0.000449301500339061, -0.03648895397782326, 0.03228515386581421, 0.035544101148843765, -0.04990888386964798, 0.039802487939596176, -0.03473106026649475, 0.02724502421915531, 0.03245691582560539, -0.0039367969147861, 0.03018241375684738, -0.11162708699703217, 0.012109476141631603, -0.016376473009586334, -0.04844581335783005, 0.010978786274790764, -0.040896058082580566, 0.04487752541899681, -0.015062522143125534, 0.04483389854431152, -0.027814675122499466, -0.01132192276418209, -0.01142179686576128, 0.03776044398546219, 0.008362212218344212, -0.014184605330228806, -0.010120552033185959, -0.0052824788726866245, -0.004190939012914896, -0.021487196907401085, -7.192986959125847e-05, -0.009528029710054398, -0.03306221589446068, 0.0028975745663046837, 0.03462915122509003, 0.08483570069074631, 0.028800133615732193, -0.07017429172992706, 0.014458464458584785, -0.02763594500720501, 0.050033342093229294, -0.1426815688610077, -0.003591827815398574, -0.02818427048623562, -0.17434650659561157, -0.07494498789310455, 0.031195364892482758, 0.045281343162059784, 0.016998305916786194, -0.029830753803253174, -0.07137065380811691, -0.024565331637859344, -0.013548726215958595, -0.06914635002613068, -0.031989686191082, 0.03293723985552788, 0.008480830118060112, 0.017188863828778267, -0.047611039131879807, 0.03554998338222504, 0.04525964707136154, -0.023743242025375366, -0.019806742668151855, -0.04613632708787918, 0.02438478358089924, 0.025655001401901245, -0.018909284844994545, 0.032585203647613525, 0.00923247542232275, 0.0015634892042726278, 0.041439201682806015, 0.01840961165726185, 0.06794717162847519, -0.046562355011701584, 0.006125192623585463, -0.024084141477942467, -0.030699705705046654, -0.008043430745601654, -0.00514978775754571, -0.024542314931750298, -0.002213048981502652, 0.000238302382058464, -0.009507733397185802, -0.0859122946858406, 0.010629002936184406, -0.007666752673685551, 0.008150245063006878, 0.005078447982668877, -0.016614889726042747, -0.10495654493570328, 0.01906730607151985, -0.010019691661000252, -0.003698193235322833, -0.005410708952695131, 0.02871973067522049, -0.03272594138979912, -0.02896774746477604, 0.012180058285593987, 0.03402766212821007, -0.01960696093738079, 0.027747469022870064, 0.04898756369948387, -0.06268344819545746, 0.02575133927166462, 0.026855124160647392, 0.059506721794605255, 0.010317113250494003, -0.0034586074762046337, 0.010623603127896786, 0.007968874648213387, 0.021532660350203514, 0.021861320361495018, 0.017548248171806335, 0.03310954570770264, -0.006181950215250254, -0.007204596418887377, 0.00855121947824955, 0.02345709502696991, -0.08851993829011917, -0.07450585067272186, 0.044208310544490814, -0.0286506786942482, -0.019851945340633392, 0.012894771061837673, 0.028011824935674667, -0.01850949414074421, -0.029960962012410164, -0.030617425218224525, 0.056575290858745575, -0.040883686393499374, 0.021380173042416573, -0.007664727512747049, -6.112972914706916e-05, -0.00875689648091793, -0.007142836228013039, 0.012592456303536892, 0.041238706558942795, 0.08111301809549332, 0.0006124056526459754, -0.03195500373840332, -0.01448537316173315, 0.004731256980448961, -0.03272421658039093, 0.04352391138672829, 0.03167259320616722, -0.053856175392866135, -0.02256016992032528, -0.06311159580945969, -0.008867708034813404, 0.010629299096763134, 0.022805875167250633, 0.014510927721858025, -0.04063156619668007, 0.04033897817134857, -0.020629629492759705, 0.02637321874499321, -0.027528056874871254, 0.0007643867866136134, -0.007373611908406019, -0.0048836818896234035, -0.021113956347107887, -5.297392107945517e-33, 0.010431918315589428, -0.007053903304040432, 0.009177781641483307, 0.04223588481545448, -0.0224097091704607, 0.03223666548728943, -0.0013544810935854912, 0.030046924948692322, -0.0339299812912941, -0.01050475612282753, -0.021802043542265892, 0.03324653580784798, 0.012992152944207191, -0.020246457308530807, 0.0051348512060940266, 0.020100252702832222, 0.008927230723202229, 0.05507712438702583, -0.04104680195450783, 0.003987544681876898, 0.0496496818959713, 0.017571913078427315, 0.010569491423666477, -0.06151149049401283, -0.02047962136566639, 0.03755057603120804, -0.008446124382317066, -0.005866967607289553, 0.014574013650417328, 0.021386099979281425, -0.02104807272553444, 0.021301109343767166, -0.030723707750439644, -0.005730463191866875, -0.026497025042772293, 0.018242061138153076, 0.012983924709260464, -0.05030018836259842, -0.03233863413333893, 0.01956992596387863, -0.0568099319934845, 0.013457857072353363, 0.07304362952709198, -0.0042633297853171825, 0.010919046588242054, 0.014195414260029793, 0.010953564196825027, -0.03945734724402428, -0.003103424794971943, 0.03720030561089516, -0.03456320986151695, 0.021246284246444702, -0.00993887148797512, -0.057612963020801544, 0.06688344478607178, -0.06266534328460693, -0.018571721389889717, 0.0052836802788078785, -0.026247601956129074, 0.05463550612330437, -0.022337153553962708, -0.03903742507100105, -0.0011275381548330188, -0.016044389456510544, 0.010087751783430576, 0.02404273860156536, 0.1644764393568039, -0.027932632714509964, 0.025578757748007774, -5.782930747955106e-05, -0.027247576043009758, 0.10012152791023254, 0.051617443561553955, -0.07193578034639359, -0.04213981330394745, 0.01870719902217388, 0.005160681903362274, -0.01788167841732502, 0.05426839739084244, -0.006714596413075924, -0.0073940809816122055, -0.039101142436265945, -0.04546963423490524, -0.01168814953416586, -0.005602918565273285, 0.008597565814852715, 0.017540788277983665, -0.027377722784876823, -0.017784414812922478, -0.0032249686773866415, -0.024938667193055153, 0.061644360423088074, -0.004722535144537687, -0.013517804443836212, -0.01946035958826542, 0.08378258347511292, -0.0641852468252182, -0.03791578859090805, -0.0006106591899879277, -0.01527467556297779, 0.03813432157039642, 0.05924293398857117, -0.02480831742286682, -0.023187436163425446, 0.033962685614824295, 0.025099411606788635, -0.0036798794753849506, 0.014310323633253574, -0.06529303640127182, -0.044705696403980255, -0.028917739167809486, -0.02350624091923237, 0.0031765224412083626, 0.049868807196617126, 0.034272450953722, -0.027205605059862137, 0.0070315576158463955, 0.015460129827260971, 0.026441706344485283, 0.039193905889987946, -0.01389452163130045, 0.07919812202453613, -0.023015914484858513, 0.002299791667610407, -0.016590185463428497, -0.021191628649830818, -0.00033421211992390454, 0.02936236746609211, -0.018472816795110703, 0.011653199791908264, 0.011028825305402279, -0.01253423746675253, 2.106367560372746e-07, 0.049328066408634186, 0.010653503239154816, 0.021004602313041687, 0.05579894036054611, -0.004361887462437153, 0.04296413064002991, -0.035218242555856705, 0.0016906997188925743, -0.05059022828936577, -0.026987047865986824, -0.039948202669620514, 0.01354780700057745, -0.0039253500290215015, 0.0265604630112648, 0.009953323751688004, -0.017682841047644615, 0.003640055889263749, -0.060560788959264755, -0.0008927387534640729, -0.06046702340245247, 0.0038085232954472303, 0.006845761090517044, 0.08521890640258789, -0.04387310892343521, 0.009154883213341236, -0.07952503114938736, -0.012336431071162224, 0.029391752555966377, 0.03471338003873825, 0.0376758798956871, 0.011235527694225311, 0.04394574463367462, -0.007789566647261381, -0.006909739691764116, -0.008785095065832138, -0.02934654802083969, 0.010265488177537918, -0.01814870536327362, -0.0014642199967056513, 0.14939405024051666, -0.0035957619547843933, 0.016356321051716805, -0.019753258675336838, 0.0031952345743775368, 0.024177443236112595, 0.06139608472585678, -0.0035715897101908922, -0.04640226438641548, -0.02249695546925068, 0.012327944859862328, 0.0073374193161726, 0.0270101185888052, -0.052293743938207626, 0.017999975010752678, -0.020733922719955444, 0.001468595233745873, -0.0022104799281805754, -0.05263657867908478, 0.03191713988780975, -0.014937079511582851, -0.012170820496976376, -0.04265180602669716, -0.012999502010643482, 0.01611703634262085, 0.07041469216346741, 0.03769736364483833, 0.0474109873175621, 1.4858381755863143e-34, -0.01028494630008936, 0.00527778547257185, 0.014670446515083313, 0.060760386288166046, -0.02619093842804432, -0.019093884155154228, 0.031922392547130585, -0.01683889515697956, 0.047219887375831604, -0.04615971818566322, -0.017975933849811554]]\n"
     ]
    }
   ],
   "source": [
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![steps](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loader = DirectoryLoader(\n",
    "#     \"docs/cs229_lectures/\", glob=\"**/*.pdf\", show_progress=True, loader_cls=PyPDFLoader\n",
    "# )\n",
    "# pages = loader.load()\n",
    "# len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\n",
    "    \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\",\n",
    ")\n",
    "pages = loader.load() \n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = text_splitter.split_documents(pages)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "persist_directory = \"docs/chromahf/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb = Chroma.from_documents(\n",
    "#     documents=splits, embedding=embeddings, persist_directory=persist_directory\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma(embedding_function=embeddings, persist_directory=persist_directory)\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"So later this quarter, we'll use the discussion sections to talk about things like convex \\noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \\nlearning algorithm for modeling time series and a few other things, so  extensions to the \\nmaterials that I'll be covering in the main  lectures. And attend ance at the discussion \\nsections is optional, okay?  \\nSo that was all I had from l ogistics. Before we move on to start talking a bit about \\nmachine learning, let me check what questions you have. Yeah?  \\nStudent : [Inaudible] R or something like that?  \\nInstructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \\nwelcome to use R, but I would strongly advi se against it, mainly because in the last \\nproblem set, we actually supply some code th at will run in Octave  but that would be \\nsomewhat painful for you to translate into R yourself. So for your other assignments, if \\nyou wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \\nworth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \\nbit more often for various reasons. Yeah?  \\nStudent : For the [inaudible] pr oject [inaudible]?  \\nInstructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \\ngroups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \\nsame regardless of the group size, so with  a larger group, you probably — I recommend\", metadata={'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content='into his office and he said, \"Oh, professo r, professor, thank you so much for your \\nmachine learning class. I learned so much from it. There\\'s this stuff that I learned in your \\nclass, and I now use every day. And it\\'s help ed me make lots of money, and here\\'s a \\npicture of my big house.\"  \\nSo my friend was very excited. He said, \"W ow. That\\'s great. I\\'m glad to hear this \\nmachine learning stuff was actually useful. So what was it that you learned? Was it \\nlogistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \\nlearned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \\nSo for those of you that don\\'t know MATLAB yet, I hope you do learn it. It\\'s not hard, \\nand we\\'ll actually have a short MATLAB tutori al in one of the discussion sections for \\nthose of you that don\\'t know it.  \\nOkay. The very last piece of logistical th ing is the discussion s ections. So discussion \\nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \\nalthough they\\'ll also be recorded and televi sed. And we\\'ll use the discussion sections \\nmainly for two things. For the next two or th ree weeks, we\\'ll use the discussion sections \\nto go over the prerequisites to this class or if some of you haven\\'t seen probability or \\nstatistics for a while or maybe algebra, we\\'ll go over those in the discussion sections as a \\nrefresher for those of you that want one.', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content=\"person's face physically attractive. There's a learning algorithm on op tical illusions, and \\nso on.  \\nAnd it goes on, so lots of fun projects. A nd take a look, then come up with your own \\nideas. But whatever you find cool and interest ing, I hope you'll be able to make machine \\nlearning a project out of it. Yeah, question?  \\nStudent : Are these gro up projects?  \\nInstructor (Andrew Ng): Oh, yes, thank you.  \\nStudent : So how many people can be in a group?  \\nInstructor (Andrew Ng): Right. So projects can be done in  groups of up to three people. \\nSo as part of forming study groups, later t oday as you get to know your classmates, I \\ndefinitely also encourage you to grab two ot her people and form a group of up to three \\npeople for your project, okay? And just start brainstorming ideas for now amongst \\nyourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \\nwith us.  \\nOkay. So one more organizational ques tion. I'm curious, how many of you know \\nMATLAB? Wow, cool, quite a lot. Okay. So as part of the — act ually how many of you \\nknow Octave or have used Octave ? Oh, okay, much smaller number.  \\nSo as part of this class, especially in the homeworks, we'll ask you to implement a few \\nprograms, a few machine learning algorithms as  part of the homeworks. And most of\", metadata={'page': 7, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.similarity_search(\"what did they say about matlab?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs: List[Document]) -> None:\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def get_metadata(docs: List[Document]) -> None:\n",
    "    for doc in docs:\n",
    "        print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"So later this quarter, we'll use the discussion sections to talk about things like convex \\noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \\nlearning algorithm for modeling time series and a few other things, so  extensions to the \\nmaterials that I'll be covering in the main  lectures. And attend ance at the discussion \\nsections is optional, okay?  \\nSo that was all I had from l ogistics. Before we move on to start talking a bit about \\nmachine learning, let me check what questions you have. Yeah?  \\nStudent : [Inaudible] R or something like that?  \\nInstructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \\nwelcome to use R, but I would strongly advi se against it, mainly because in the last \\nproblem set, we actually supply some code th at will run in Octave  but that would be \\nsomewhat painful for you to translate into R yourself. So for your other assignments, if \\nyou wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \\nworth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \\nbit more often for various reasons. Yeah?  \\nStudent : For the [inaudible] pr oject [inaudible]?  \\nInstructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \\ngroups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \\nsame regardless of the group size, so with  a larger group, you probably — I recommend\", metadata={'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}), Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "docs = vectordb.max_marginal_relevance_search(question, k=2, fetch_k=3)\n",
    "print(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "get_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \n",
      "without even knowing it.  \n",
      "And of course, learning algorithms are also  doing things like giving us a growing \n",
      "understanding of the human genome. So if so meday we ever find a cure for cancer, I bet \n",
      "learning algorithms will have had a large role in that. That's sort of the thing that Tom \n",
      "works on, yes?  \n",
      "So in teaching this class, I sort of have thre e goals. One of them is just to I hope convey \n",
      "some of my own excitement a bout machine learning to you.  \n",
      "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\n",
      "the-art machine learning algorithms to whatev er problems you're interested in. And if you \n",
      "ever need to build a system for reading zi p codes, you'll know how to do that by the end \n",
      "of this class.  \n",
      "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \n",
      "doing research in machine learning, but by the c onclusion of this class,  I hope that all of \n",
      "you will actually be well qualified to star t doing research in machine learning, okay?  \n",
      "So let's say a few words about logistics. The prerequisites of this class are written on one \n",
      "of the handouts, are as follows: In this class, I'm going to assume that all of you have sort \n",
      "of basic knowledge of computer science and kn owledge of the basic computer skills and \n",
      "principles. So I assume all of you know what big?O notation, that all of you know about\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Similarly, every time you write a check, I ac tually don't know the number for this, but a \n",
      "significant fraction of checks that you write are processed by a learning algorithm that's \n",
      "learned to read the digits, so the dolla r amount that you wrote down on your check. So \n",
      "every time you write a check, there's anot her learning algorithm that you're probably \n",
      "using without even being aware of it.  \n",
      "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \n",
      "companies like eBay as well that do electr onic transactions, there's a good chance that \n",
      "there's a learning algorithm in the backgr ound trying to figure out if, say, your credit \n",
      "card's been stolen or if someone's engaging in a fraudulent transaction.  \n",
      "If you use a website like Amazon or Netflix that will often recommend books for you to \n",
      "buy or movies for you to rent or whatever , these are other examples of learning \n",
      "algorithms that have learned what sorts of th ings you like to buy or what sorts of movies \n",
      "you like to watch and can therefore give  customized recommendations to you.  \n",
      "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \n",
      "to explain to me some learning algorithm in th e innards of my car th at's sort of doing its \n",
      "best to optimize my driving performan ce for fuel efficiency or something.  \n",
      "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \n",
      "without even knowing it.\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression on page 3?\"\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=2,\n",
    "    filter={\"page\": 3},\n",
    ")\n",
    "\n",
    "pretty_print_docs(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "get_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    # AttributeInfo(\n",
    "    #     name=\"source\",\n",
    "    #     description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "    #     type=\"string\",\n",
    "    # ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "base_llm = OpenAI(temperature=0)\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    base_llm, vectordb, document_content_description, metadata_field_info, verbose=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alli/miniconda3/envs/openai/lib/python3.11/site-packages/langchain/chains/llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='regression' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='page', value=3) limit=None\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression on page 3?\"\n",
    "\n",
    "docs = retriever.get_relevant_documents(question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \n",
      "without even knowing it.  \n",
      "And of course, learning algorithms are also  doing things like giving us a growing \n",
      "understanding of the human genome. So if so meday we ever find a cure for cancer, I bet \n",
      "learning algorithms will have had a large role in that. That's sort of the thing that Tom \n",
      "works on, yes?  \n",
      "So in teaching this class, I sort of have thre e goals. One of them is just to I hope convey \n",
      "some of my own excitement a bout machine learning to you.  \n",
      "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\n",
      "the-art machine learning algorithms to whatev er problems you're interested in. And if you \n",
      "ever need to build a system for reading zi p codes, you'll know how to do that by the end \n",
      "of this class.  \n",
      "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \n",
      "doing research in machine learning, but by the c onclusion of this class,  I hope that all of \n",
      "you will actually be well qualified to star t doing research in machine learning, okay?  \n",
      "So let's say a few words about logistics. The prerequisites of this class are written on one \n",
      "of the handouts, are as follows: In this class, I'm going to assume that all of you have sort \n",
      "of basic knowledge of computer science and kn owledge of the basic computer skills and \n",
      "principles. So I assume all of you know what big?O notation, that all of you know about\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Similarly, every time you write a check, I ac tually don't know the number for this, but a \n",
      "significant fraction of checks that you write are processed by a learning algorithm that's \n",
      "learned to read the digits, so the dolla r amount that you wrote down on your check. So \n",
      "every time you write a check, there's anot her learning algorithm that you're probably \n",
      "using without even being aware of it.  \n",
      "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \n",
      "companies like eBay as well that do electr onic transactions, there's a good chance that \n",
      "there's a learning algorithm in the backgr ound trying to figure out if, say, your credit \n",
      "card's been stolen or if someone's engaging in a fraudulent transaction.  \n",
      "If you use a website like Amazon or Netflix that will often recommend books for you to \n",
      "buy or movies for you to rent or whatever , these are other examples of learning \n",
      "algorithms that have learned what sorts of th ings you like to buy or what sorts of movies \n",
      "you like to watch and can therefore give  customized recommendations to you.  \n",
      "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \n",
      "to explain to me some learning algorithm in th e innards of my car th at's sort of doing its \n",
      "best to optimize my driving performan ce for fuel efficiency or something.  \n",
      "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \n",
      "without even knowing it.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "principles. So I assume all of you know what big?O notation, that all of you know about \n",
      "sort of data structures like  queues, stacks, binary trees , and that all of you know enough \n",
      "programming skills to, like, write a simple co mputer program. And it turns out that most\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "get_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alli/miniconda3/envs/openai/lib/python3.11/site-packages/langchain/chains/llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='regression' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='page', value=1), Comparison(comparator=<Comparator.LTE: 'lte'>, attribute='page', value=10)]) limit=None\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 6, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 7, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 10, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "question = (\n",
    "    \"what did they say about regression between pages one and ten?\"\n",
    ")\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "get_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(base_llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "\"I personally end up using MATLAB quite a bit more often for various reasons.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "\"So one more organizational question. I'm curious, how many of you know MATLAB? Wow, cool, quite a lot. Okay. So as part of the — actually how many of you know Octave or have used Octave ? Oh, okay, much smaller number.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "So later this quarter, we'll use the discussion sections to talk about things like convex \n",
      "optimization, to talk a little bit about hidde n Markov models, which is a type of machine \n",
      "learning algorithm for modeling time series and a few other things, so  extensions to the \n",
      "materials that I'll be covering in the main  lectures. And attend ance at the discussion \n",
      "sections is optional, okay?  \n",
      "So that was all I had from l ogistics. Before we move on to start talking a bit about \n",
      "machine learning, let me check what questions you have. Yeah?  \n",
      "Student : [Inaudible] R or something like that?  \n",
      "Instructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \n",
      "welcome to use R, but I would strongly advi se against it, mainly because in the last \n",
      "problem set, we actually supply some code th at will run in Octave  but that would be \n",
      "somewhat painful for you to translate into R yourself. So for your other assignments, if \n",
      "you wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \n",
      "worth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \n",
      "bit more often for various reasons. Yeah?  \n",
      "Student : For the [inaudible] pr oject [inaudible]?  \n",
      "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \n",
      "groups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \n",
      "same regardless of the group size, so with  a larger group, you probably — I recommend\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learning class. I learned so much from it. There's this stuff that I learned in your \n",
      "class, and I now use every day. And it's help ed me make lots of money, and here's a \n",
      "picture of my big house.\"  \n",
      "So my friend was very excited. He said, \"W ow. That's great. I'm glad to hear this \n",
      "machine learning stuff was actually useful. So what was it that you learned? Was it \n",
      "logistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \n",
      "learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
      "and we'll actually have a short MATLAB tutori al in one of the discussion sections for \n",
      "those of you that don't know it.  \n",
      "Okay. The very last piece of logistical th ing is the discussion s ections. So discussion \n",
      "sections will be taught by the TAs, and atte ndance at discussion sections is optional, \n",
      "although they'll also be recorded and televi sed. And we'll use the discussion sections \n",
      "mainly for two things. For the next two or th ree weeks, we'll use the discussion sections \n",
      "to go over the prerequisites to this class or if some of you haven't seen probability or \n",
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "person's face physically attractive. There's a learning algorithm on op tical illusions, and \n",
      "so on.  \n",
      "And it goes on, so lots of fun projects. A nd take a look, then come up with your own \n",
      "ideas. But whatever you find cool and interest ing, I hope you'll be able to make machine \n",
      "learning a project out of it. Yeah, question?  \n",
      "Student : Are these gro up projects?  \n",
      "Instructor (Andrew Ng): Oh, yes, thank you.  \n",
      "Student : So how many people can be in a group?  \n",
      "Instructor (Andrew Ng): Right. So projects can be done in  groups of up to three people. \n",
      "So as part of forming study groups, later t oday as you get to know your classmates, I \n",
      "definitely also encourage you to grab two ot her people and form a group of up to three \n",
      "people for your project, okay? And just start brainstorming ideas for now amongst \n",
      "yourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \n",
      "with us.  \n",
      "Okay. So one more organizational ques tion. I'm curious, how many of you know \n",
      "MATLAB? Wow, cool, quite a lot. Okay. So as part of the — act ually how many of you \n",
      "know Octave or have used Octave ? Oh, okay, much smaller number.  \n",
      "So as part of this class, especially in the homeworks, we'll ask you to implement a few \n",
      "programs, a few machine learning algorithms as  part of the homeworks. And most of\n"
     ]
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(question, k=4)\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 7, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "None\n",
      "{'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 7, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_metadata(compressed_docs))\n",
    "print(get_metadata(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine threshold score and Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.9}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alli/miniconda3/envs/openai/lib/python3.11/site-packages/langchain/vectorstores/base.py:266: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine MMR and Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alli/miniconda3/envs/openai/lib/python3.11/site-packages/langchain/chains/llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type=\"mmr\"),\n",
    ")\n",
    "\n",
    "docs = compression_retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "\"I personally end up using MATLAB quite a bit more often for various reasons.\"\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RetrievalQA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Default Chain Type (Stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what did they say about matlab?',\n",
       " 'result': '\\n\\nMatlab is a programming language and environment that is commonly used in data analysis, visualization, and numerical computing. It is widely used in scientific and engineering fields, including physics, engineering, and finance. It is often used to create interactive visualizations and perform complex numerical computations. It is also used to develop and test algorithms, which are mathematical procedures that can be used to solve complex problems. It is a powerful tool for data analysis and can be used to analyze large datasets, perform statistical analysis, and create complex visualizations. It is also used to develop and test algorithms, which are mathematical procedures that can be used to solve complex problems.',\n",
       " 'source_documents': [Document(page_content=\"So later this quarter, we'll use the discussion sections to talk about things like convex \\noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \\nlearning algorithm for modeling time series and a few other things, so  extensions to the \\nmaterials that I'll be covering in the main  lectures. And attend ance at the discussion \\nsections is optional, okay?  \\nSo that was all I had from l ogistics. Before we move on to start talking a bit about \\nmachine learning, let me check what questions you have. Yeah?  \\nStudent : [Inaudible] R or something like that?  \\nInstructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \\nwelcome to use R, but I would strongly advi se against it, mainly because in the last \\nproblem set, we actually supply some code th at will run in Octave  but that would be \\nsomewhat painful for you to translate into R yourself. So for your other assignments, if \\nyou wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \\nworth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \\nbit more often for various reasons. Yeah?  \\nStudent : For the [inaudible] pr oject [inaudible]?  \\nInstructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \\ngroups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \\nsame regardless of the group size, so with  a larger group, you probably — I recommend\", metadata={'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       "  Document(page_content=\"turns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \\nBut in contrast, if you want to do things like to get software to fl y a helicopter or have \\nsoftware recognize handwritten digits, one very  successful approach is to use a learning \\nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \\nAnd in fact, handwritten digit recognition, this is pretty much the only approach that \\nworks well. It uses applications that are hard to program by hand.  \\nLearning algorithms has also made I guess sign ificant inroads in what's sometimes called \\ndatabase mining. So, for example, with the growth of IT and computers, increasingly \\nmany hospitals are keeping around medical reco rds of what sort of patients, what \\nproblems they had, what their prognoses was,  what the outcome was. And taking all of \\nthese medical records, which started to be digitized only about maybe 15 years, applying \\nlearning algorithms to them can turn raw medi cal records into what I might loosely call \\nmedical knowledge in which we start to detect trends in medical practice and even start to \\nalter medical practice as a result of me dical knowledge that's derived by applying \\nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \\nover the last 15, 20 years in an electronic format.  \\nTurns out that most of you probably use learning algorithms — I don't know — I think\", metadata={'page': 2, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "result = qa_chain({\"query\": question}) \n",
    "\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "So later this quarter, we'll use the discussion sections to talk about things like convex \n",
      "optimization, to talk a little bit about hidde n Markov models, which is a type of machine \n",
      "learning algorithm for modeling time series and a few other things, so  extensions to the \n",
      "materials that I'll be covering in the main  lectures. And attend ance at the discussion \n",
      "sections is optional, okay?  \n",
      "So that was all I had from l ogistics. Before we move on to start talking a bit about \n",
      "machine learning, let me check what questions you have. Yeah?  \n",
      "Student : [Inaudible] R or something like that?  \n",
      "Instructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \n",
      "welcome to use R, but I would strongly advi se against it, mainly because in the last \n",
      "problem set, we actually supply some code th at will run in Octave  but that would be \n",
      "somewhat painful for you to translate into R yourself. So for your other assignments, if \n",
      "you wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \n",
      "worth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \n",
      "bit more often for various reasons. Yeah?  \n",
      "Student : For the [inaudible] pr oject [inaudible]?  \n",
      "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \n",
      "groups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \n",
      "same regardless of the group size, so with  a larger group, you probably — I recommend\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "turns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n",
      "But in contrast, if you want to do things like to get software to fl y a helicopter or have \n",
      "software recognize handwritten digits, one very  successful approach is to use a learning \n",
      "algorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n",
      "And in fact, handwritten digit recognition, this is pretty much the only approach that \n",
      "works well. It uses applications that are hard to program by hand.  \n",
      "Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \n",
      "database mining. So, for example, with the growth of IT and computers, increasingly \n",
      "many hospitals are keeping around medical reco rds of what sort of patients, what \n",
      "problems they had, what their prognoses was,  what the outcome was. And taking all of \n",
      "these medical records, which started to be digitized only about maybe 15 years, applying \n",
      "learning algorithms to them can turn raw medi cal records into what I might loosely call \n",
      "medical knowledge in which we start to detect trends in medical practice and even start to \n",
      "alter medical practice as a result of me dical knowledge that's derived by applying \n",
      "learning algorithms to the sorts of medical r ecords that hospitals have just been building \n",
      "over the last 15, 20 years in an electronic format.  \n",
      "Turns out that most of you probably use learning algorithms — I don't know — I think\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 2, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "get_metadata(result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The students were told that MATLAB was a good tool to use for their project, but that it was not necessary to use it for the term project. The instructor also stated that he personally used MATLAB more often than R.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result'].strip('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting Prompt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import BaseRetrievalQA\n",
    "\n",
    "\n",
    "def get_qa_result(question: str, qa_chain: BaseRetrievalQA) -> str:\n",
    "    result = qa_chain({\"query\": question})\n",
    "\n",
    "    return result[\"result\"]\n",
    "\n",
    "\n",
    "qa_result = lambda question, qa_chain: qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum. Keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "# Remove Helpful for Falcon 7b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    chat_llm,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The instructor advised against using R for the problem set because the code provided would be difficult to translate. They mentioned that MATLAB is worth learning and that they personally use it more often. Thanks for asking!'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_qa_result(\"what did they say about matlab?\", qa_chain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know. Thanks for asking!\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_qa_result(\"What is the current yam price in Mile 12 market?\", qa_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Map Reduce Chain Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    chat_llm,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"map_reduce\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is no mention of MATLAB in the provided text.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_qa_result(\"what did they say about matlab?\", qa_chain_mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Refine Chain Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_refine = RetrievalQA.from_chain_type(\n",
    "    chat_llm,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type=\"refine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I apologize for the confusion earlier. \"refine_template\" is not a recognized term or function in MATLAB. It is possible that it is a custom function or variable specific to a particular code or project. Without further information or context, it is difficult to provide a specific explanation. If you can provide more details or clarify your question, I would be happy to help.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_qa_result(\"what did they say about matlab?\", qa_chain_refine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_qa_result(\"What are major topics for this class?\", qa_chain_refine) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversation history is not being stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.retrieval_qa.base import BaseRetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "def get_qa_result(question: str, qa_chain: BaseRetrievalQA) -> str:\n",
    "    result = qa_chain({\"query\": question})\n",
    "\n",
    "    return result[\"result\"]\n",
    "\n",
    "\n",
    "chat_llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum. Keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    chat_llm,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The topics covered include statistics, algebra, extensions in machine learning, and the late homework policy. Thanks for asking!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_qa_result(\"what are the topics covered?\", qa_chain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The frequency of each topic being discussed is not mentioned in the given context. \\nThanks for asking!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_qa_result(\"Tell me how often each of these topics were treated?\", qa_chain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from pprint import pprint\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True,\n",
    "    memory_key='chat_history'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[]), output_key=None, input_key=None, return_messages=True, human_prefix='Human', ai_prefix='AI', memory_key='chat_history')\n"
     ]
    }
   ],
   "source": [
    "pprint(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa_chain_conv = ConversationalRetrievalChain.from_llm(\n",
    "    chat_llm,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3}),\n",
    "    # return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what are the topics covered?',\n",
       " 'chat_history': [HumanMessage(content='what are the topics covered?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The topics covered include statistics, algebra, machine learning, and extensions of the material taught in the main lectures. Thanks for asking!', additional_kwargs={}, example=False)],\n",
       " 'answer': 'The topics covered include statistics, algebra, machine learning, and extensions of the material taught in the main lectures. Thanks for asking!'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain_conv({\"question\": \"what are the topics covered?\"})\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The topics covered include statistics, algebra, machine learning, and extensions of the material taught in the main lectures. Thanks for asking!'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='what are the topics covered?', additional_kwargs={}, example=False), AIMessage(content='The topics covered include statistics, algebra, machine learning, and extensions of the material taught in the main lectures. Thanks for asking!', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, human_prefix='Human', ai_prefix='AI', memory_key='chat_history')\n"
     ]
    }
   ],
   "source": [
    "pprint(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what are the topics covered?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The topics covered include statistics, algebra, machine learning, and extensions of the material taught in the main lectures. Thanks for asking!', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = qa_chain_conv({\"question\": \"Tell me how often each of these topics were treated?\"})\n",
    "# result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Tell me more about these topics?',\n",
       " 'chat_history': [HumanMessage(content='what are the topics covered?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The topics covered include statistics, algebra, machine learning, and extensions of the material taught in the main lectures. Thanks for asking!', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='Tell me more about these topics?', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='The topics covered in this class include statistics, algebra, machine learning, supervised learning, and housing price prediction. The class also discusses extensions of the material taught in the main lectures and emphasizes the importance of independent work on homework problems without referring to notes or solutions from previous years. The instructor also mentions the late homework policy. Thanks for asking!', additional_kwargs={}, example=False)],\n",
       " 'answer': 'The topics covered in this class include statistics, algebra, machine learning, supervised learning, and housing price prediction. The class also discusses extensions of the material taught in the main lectures and emphasizes the importance of independent work on homework problems without referring to notes or solutions from previous years. The instructor also mentions the late homework policy. Thanks for asking!'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain_conv({\"question\": \"Tell me more about these topics?\"})\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The topics covered in this class include statistics, algebra, machine learning, supervised learning, and housing price prediction. The class also discusses extensions of the material taught in the main lectures and emphasizes the importance of independent work on homework problems without referring to notes or solutions from previous years. The instructor also mentions the late homework policy. Thanks for asking!'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='what are the topics covered?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The topics covered include statistics, algebra, machine learning, and extensions of the material taught in the main lectures. Thanks for asking!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Tell me more about these topics?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The topics covered in this class include statistics, algebra, machine learning, supervised learning, and housing price prediction. The class also discusses extensions of the material taught in the main lectures and emphasizes the importance of independent work on homework problems without referring to notes or solutions from previous years. The instructor also mentions the late homework policy. Thanks for asking!', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.sentence_transformer import (\n",
    "    ContentHandler,\n",
    "    SagemakerEndpointEmbeddingsJumpStart,\n",
    ")\n",
    "import boto3\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "emb_parameters = {\"device\": \"cuda\"}\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddingsJumpStart(\n",
    "    # credentials_profile_name=\"credentials-profile-name\",\n",
    "    endpoint_name=\"sentence-transformers-all-mpnet-base-v2\",\n",
    "    region_name=aws_region,\n",
    "    content_handler=content_handler,\n",
    "    model_kwargs=emb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06125985085964203, -0.012730025686323643, 0.0026824057567864656, -0.011465264484286308, 0.05068375542759895, 0.031877126544713974, -0.054364461451768875, 0.01286295522004366, -0.0719950795173645, 0.0407085120677948, -0.051409702748060226, 0.07480666786432266, -0.027688778936862946, 0.04893019422888756, -0.04801536351442337, -0.031737539917230606, 0.0098807904869318, 0.00830261129885912, 0.08461165428161621, -0.015256528742611408, -0.027286618947982788, 0.043101273477077484, 0.016588855534791946, -0.0009410082129761577, 0.06394019722938538, -0.023366713896393776, 0.009754469618201256, 0.02499263547360897, -0.009198229759931564, 0.028949543833732605, 0.029997657984495163, -0.036026209592819214, 0.0054996199905872345, 0.027064844965934753, 1.3621404377772706e-06, 0.023159606382250786, 0.0032908061984926462, 0.0027586771175265312, -0.03451158478856087, 0.0014546978054568172, -0.018534166738390923, -0.04215547814965248, 0.051722750067710876, 0.0038519613444805145, -0.021167853847146034, 0.01413649134337902, 0.026663050055503845, -0.027007346972823143, 0.045138683170080185, -0.03686472028493881, 0.00884039793163538, 0.0452885627746582, -0.004341334570199251, -0.0619208924472332, 0.10748466104269028, -0.040221016854047775, -0.03185592591762543, 0.055083323270082474, 0.03458996117115021, 0.0030161519534885883, 0.04430912435054779, 0.07384044677019119, -0.01449501607567072, 0.0020232084207236767, 0.018901702016592026, -0.010215211659669876, -0.004954881966114044, -0.057787440717220306, 0.02794560045003891, 0.0024875171948224306, 0.021346230059862137, -0.048296015709638596, -0.02729460597038269, 0.0765833780169487, -0.007141355890780687, 0.044199444353580475, -0.04359757900238037, 0.018766598775982857, 0.009538955055177212, -0.031561002135276794, 0.020228657871484756, 0.02613130956888199, 0.0038307374343276024, 0.026146315038204193, -0.045112494379282, 0.06285671889781952, 0.017009256407618523, 0.010410810820758343, -0.06277649104595184, 0.028154240921139717, 0.03492611646652222, -0.00047976773930713534, 0.029604891315102577, 0.0240954477339983, -0.038404908031225204, -0.03927348554134369, -0.019615614786744118, -0.006657612510025501, -0.03605576604604721, 0.06309423595666885, -0.003569625550881028, 0.004051190800964832, 0.007926453836262226, 0.03019634447991848, -0.004986090585589409, 0.03680188208818436, 0.025098705664277077, 0.08525368571281433, 0.014152717776596546, -0.012752795591950417, 0.005850030109286308, -0.0039433944039046764, 0.01631813868880272, -0.06480740755796432, 0.038763996213674545, -0.009271842427551746, 0.02428382821381092, 0.03931275010108948, -0.010399368591606617, 0.013874033465981483, -0.10203659534454346, 0.02869540825486183, 0.009640483185648918, 0.04541323333978653, -0.01141499262303114, 0.02381562814116478, 0.0017979509430006146, 0.028710750862956047, -0.009167933836579323, -0.031217394396662712, -0.032582838088274, 0.008502106182277203, -0.0006144960061646998, -0.033356789499521255, 0.03322388231754303, 0.04024193063378334, 0.004761007614433765, -0.05783801153302193, 0.06828854233026505, -0.010615733452141285, 0.012471523135900497, -0.09278722107410431, 0.019242171198129654, 0.020449800416827202, 0.004211681894958019, 0.04869656264781952, 0.04665878787636757, -0.09846444427967072, 0.009791642427444458, -0.003747699549421668, 0.0181223563849926, 0.010994303971529007, 0.023809513077139854, -0.00016066392709035426, 0.03945555165410042, 0.016400393098592758, -0.0713014230132103, -0.011260309256613255, 0.01688804291188717, 0.03519238531589508, -0.014879189431667328, -0.027346542105078697, -0.02518710494041443, -0.03161429986357689, 0.010939315892755985, 0.048018038272857666, -0.002696095732972026, -0.01299811340868473, -0.015595320612192154, -0.014799443073570728, 0.038693834096193314, 0.020104289054870605, -0.024356532841920853, 0.01347686443477869, 0.0027267448604106903, 0.0026073206681758165, -0.02803533896803856, -0.02101377584040165, 0.04500137269496918, -0.02103426307439804, 0.05342060700058937, 0.038234300911426544, -0.018225431442260742, -0.028051678091287613, -0.008952905423939228, 0.02158704586327076, -0.06964807212352753, 0.00035699165891855955, 0.006636136677116156, -0.00927781406790018, -0.0066790212877094746, 0.06396621465682983, 0.02790035307407379, 0.03213496133685112, -0.009875317104160786, 0.031912241131067276, -0.0031180165242403746, -0.05063094571232796, -0.012769361957907677, -0.034043554216623306, -0.019848961383104324, 0.0024085964541882277, 0.04130374640226364, 0.1074737012386322, 0.007315109483897686, -0.007012808229774237, -0.004995264578610659, -0.00654949713498354, -0.03649444133043289, 0.020564770326018333, -0.044837433844804764, 0.0003226860717404634, -0.017360670492053032, 0.007923412136733532, -0.0011015812633559108, -0.034926582127809525, 0.024217315018177032, 0.039147183299064636, -0.02184906415641308, 0.012020986527204514, 0.015033029019832611, 0.06980132311582565, -0.06443730741739273, 0.026882242411375046, -0.08021460473537445, -0.0005908902967348695, -0.006077021826058626, -0.010915723629295826, -0.01296322513371706, -0.004070756025612354, -0.011647294275462627, 0.010941700078547001, 0.007760775275528431, -0.0038898801431059837, 0.03584941476583481, 0.0010954886674880981, 0.0317392498254776, -0.033586714416742325, -0.002193619729951024, -0.06086224317550659, -0.006333177909255028, 0.09285576641559601, 0.061198193579912186, 0.0009558252640999854, 0.04577077552676201, 0.03943140059709549, 0.033349331468343735, -0.008732016198337078, 0.025315027683973312, 0.016051651909947395, 0.0465053915977478, 0.011868967674672604, -0.04607629030942917, 0.015603764913976192, 0.032918184995651245, 0.0500180721282959, 0.014204330742359161, -0.030694713816046715, -0.02737189643085003, -0.05599522218108177, 0.006026637740433216, 0.00598230492323637, 0.017239965498447418, -0.036939822137355804, -0.01778317801654339, 0.009314346127212048, -0.0113661615177989, 0.050789739936590195, 0.013052131049335003, -0.007943052798509598, 0.013559235259890556, 0.012264518067240715, -0.0006528854719363153, -0.022131025791168213, -0.019548684358596802, 0.01460591796785593, -0.007422471418976784, -0.03465611860156059, 0.006944091059267521, 0.004880448337644339, 0.011118216440081596, -0.027537167072296143, -0.02308562584221363, -0.010851038619875908, -0.009479068219661713, 0.07159440219402313, 0.04663969203829765, 0.028080519288778305, 0.021478500217199326, -0.046519145369529724, -0.016200346872210503, -0.031434640288352966, -0.022194553166627884, 0.02520909160375595, 0.012091566808521748, -0.002404298633337021, 0.0657774955034256, -0.023660698905587196, -0.002559258136898279, -0.03965131565928459, 0.04060234874486923, 0.020819002762436867, 0.01960224285721779, -0.008173062466084957, -0.004717246629297733, -0.05433030053973198, 0.008864623494446278, -0.023891441524028778, -0.011330879293382168, 0.011662601493299007, -0.0560913048684597, -0.008384059183299541, 0.02338794805109501, -0.01269732415676117, 0.051377784460783005, -0.01875271275639534, -0.06147497147321701, -0.0492524616420269, 0.01180854719132185, 0.040433067828416824, 0.04895941913127899, -0.014430945739150047, -0.035350389778614044, -0.04208894446492195, 0.0043820892460644245, -0.02531891129910946, -0.09835024178028107, -0.009146039374172688, 0.04875538498163223, 0.046525560319423676, 0.005679427180439234, -0.01074305921792984, 0.017784783616662025, -0.035314809530973434, 0.016950450837612152, 0.05485489219427109, -0.015630247071385384, 0.037164654582738876, 0.0057231043465435505, -0.006412621587514877, 0.007370185572654009, 0.01034693792462349, -0.06850328296422958, 0.008011127822101116, -0.05791535973548889, -0.004988204687833786, -0.055812619626522064, -0.04295536130666733, -0.021890664473176003, -0.02308807708323002, 0.0018639957997947931, 0.014880103059113026, -0.017660729587078094, 0.0032849982380867004, 0.028946613892912865, 0.002734259469434619, -0.049109600484371185, -0.018840696662664413, -0.10042800009250641, -0.05577237159013748, -0.03943643346428871, -0.01999923214316368, -0.05475717782974243, 0.004679711069911718, -0.007016902789473534, 0.021061163395643234, 0.017598340287804604, 0.0020651789382100105, -0.021489281207323074, -0.02883932925760746, -0.09358778595924377, -0.049603670835494995, -0.019588652998209, 0.002162365708500147, 0.012463225051760674, -0.02758120372891426, -0.013773342594504356, -0.024004938080906868, 0.0201543141156435, 0.00922288279980421, 0.05784577131271362, -0.06847222149372101, -0.009109867736697197, -0.008460513316094875, 0.04128076136112213, -0.00022500011255033314, 0.01957434043288231, -0.06597933918237686, 0.02598203718662262, -0.02214440517127514, -0.0008158443961292505, -0.01394557859748602, -0.014771334826946259, 0.016565391793847084, 0.00044930927106179297, -0.03648893162608147, 0.032285165041685104, 0.03554411232471466, -0.04990885779261589, 0.03980247303843498, -0.03473106026649475, 0.02724502608180046, 0.032456908375024796, -0.003936793655157089, 0.030182411894202232, -0.11162708699703217, 0.012109445407986641, -0.016376491636037827, -0.048445820808410645, 0.010978794656693935, -0.04089606553316116, 0.04487752914428711, -0.015062524937093258, 0.04483389854431152, -0.027814675122499466, -0.011321929283440113, -0.011421808041632175, 0.03776044026017189, 0.008362198248505592, -0.014184605330228806, -0.010120538994669914, -0.005282491911202669, -0.004190943669527769, -0.021487198770046234, -7.192815246526152e-05, -0.009528038091957569, -0.03306221216917038, 0.0028975745663046837, 0.034629158675670624, 0.0848357155919075, 0.028800126165151596, -0.07017429172992706, 0.014458456076681614, -0.02763594686985016, 0.05003335699439049, -0.1426815688610077, -0.0035918259527534246, -0.028184279799461365, -0.17434650659561157, -0.07494499534368515, 0.031195370480418205, 0.04528132453560829, 0.016998320817947388, -0.029830746352672577, -0.07137065380811691, -0.02456534467637539, -0.013548723421990871, -0.06914635002613068, -0.03198966011404991, 0.03293725475668907, 0.008480851538479328, 0.01718886010348797, -0.047611042857170105, 0.03554998338222504, 0.045259635895490646, -0.023743251338601112, -0.01980673335492611, -0.04613634943962097, 0.02438477799296379, 0.025655008852481842, -0.018909288570284843, 0.032585203647613525, 0.009232490323483944, 0.0015634899027645588, 0.04143919423222542, 0.0184096060693264, 0.067947156727314, -0.04656235873699188, 0.006125178188085556, -0.02408413589000702, -0.03069969080388546, -0.008043426088988781, -0.005149782169610262, -0.024542324244976044, -0.0022130459547042847, 0.0002382960228715092, -0.009507723152637482, -0.08591233193874359, 0.010628998279571533, -0.007666758261620998, 0.008150250650942326, 0.00507844565436244, -0.016614893451333046, -0.10495654493570328, 0.0190673116594553, -0.010019700042903423, -0.003698193235322833, -0.005410710349678993, 0.028719734400510788, -0.032725922763347626, -0.028967753052711487, 0.012180075980722904, 0.03402765467762947, -0.019606979563832283, 0.027747472748160362, 0.048987578600645065, -0.06268344074487686, 0.025751352310180664, 0.026855140924453735, 0.05950671061873436, 0.010317112319171429, -0.003458620049059391, 0.010623584501445293, 0.007968880236148834, 0.02153264731168747, 0.02186131291091442, 0.017548251897096634, 0.03310956060886383, -0.006181948818266392, -0.007204599678516388, 0.008551198989152908, 0.023457087576389313, -0.08851993829011917, -0.07450587302446365, 0.04420829936861992, -0.028650686144828796, -0.01985195279121399, 0.012894755229353905, 0.028011824935674667, -0.018509499728679657, -0.02996096946299076, -0.030617423355579376, 0.056575290858745575, -0.04088367894291878, 0.021380173042416573, -0.007664705626666546, -6.112103437772021e-05, -0.008756887167692184, -0.007142848335206509, 0.012592462822794914, 0.041238706558942795, 0.08111301809549332, 0.0006123787607066333, -0.031954988837242126, -0.014485378749668598, 0.004731250461190939, -0.032724205404520035, 0.043523915112018585, 0.03167259320616722, -0.053856149315834045, -0.022560173645615578, -0.06311159580945969, -0.008867714554071426, 0.010629295371472836, 0.022805877029895782, 0.014510923996567726, -0.04063158109784126, 0.040338970720767975, -0.02062962017953396, 0.02637321874499321, -0.027528049424290657, 0.0007644084980711341, -0.007373569067567587, -0.0048836711794137955, -0.021113937720656395, -5.2973924752875014e-33, 0.010431906208395958, -0.007053925655782223, 0.00917777232825756, 0.04223591089248657, -0.022409701719880104, 0.03223666176199913, -0.0013544784160330892, 0.030046910047531128, -0.033929985016584396, -0.010504764504730701, -0.02180204540491104, 0.03324652835726738, 0.012992152944207191, -0.020246461033821106, 0.005134867038577795, 0.020100237801671028, 0.008927231654524803, 0.05507712438702583, -0.04104680195450783, 0.003987532574683428, 0.049649663269519806, 0.017571909353137016, 0.01056949608027935, -0.061511505395174026, -0.020479626953601837, 0.037550583481788635, -0.00844612531363964, -0.0058669778518378735, 0.014574016444385052, 0.021386094391345978, -0.021048078313469887, 0.021301113069057465, -0.030723722651600838, -0.005730449687689543, -0.02649703063070774, 0.01824204809963703, 0.012983931228518486, -0.05030015856027603, -0.032338641583919525, 0.019569939002394676, -0.056809909641742706, 0.013457868248224258, 0.07304362207651138, -0.004263322800397873, 0.010919042862951756, 0.014195406809449196, 0.010953560471534729, -0.039457354694604874, -0.0031034310813993216, 0.03720030561089516, -0.03456322103738785, 0.02124628610908985, -0.009938870556652546, -0.057612959295511246, 0.06688342243432999, -0.06266535073518753, -0.018571728840470314, 0.00528366444632411, -0.026247618719935417, 0.054635487496852875, -0.022337166592478752, -0.03903743997216225, -0.0011275217402726412, -0.016044385731220245, 0.010087738744914532, 0.02404274232685566, 0.1644764393568039, -0.02793261967599392, 0.025578754022717476, -5.784790846519172e-05, -0.027247566729784012, 0.10012152045965195, 0.051617443561553955, -0.07193579524755478, -0.04213981330394745, 0.018707185983657837, 0.00516069820150733, -0.017881687730550766, 0.05426839739084244, -0.006714589428156614, -0.007394092623144388, -0.03910113498568535, -0.04546963796019554, -0.011688148602843285, -0.00560291763395071, 0.00859756302088499, 0.017540793865919113, -0.027377711609005928, -0.017784424126148224, -0.0032249789219349623, -0.024938665330410004, 0.061644360423088074, -0.004722541198134422, -0.013517801649868488, -0.019460363313555717, 0.08378257602453232, -0.06418522447347641, -0.03791579604148865, -0.0006106497021391988, -0.015274683013558388, 0.038134314119815826, 0.05924295634031296, -0.02480831742286682, -0.023187439888715744, 0.033962689340114594, 0.025099419057369232, -0.0036798773799091578, 0.014310338534414768, -0.06529302895069122, -0.044705700129270554, -0.028917726129293442, -0.02350625768303871, 0.0031765352468937635, 0.04986879974603653, 0.0342724584043026, -0.02720559947192669, 0.007031549699604511, 0.015460126101970673, 0.026441698893904686, 0.039193909615278244, -0.013894510455429554, 0.07919812202453613, -0.023015908896923065, 0.00229979632422328, -0.01659020595252514, -0.02119162492454052, -0.0003342202689964324, 0.029362356290221214, -0.01847282610833645, 0.011653204448521137, 0.01102883368730545, -0.012534262612462044, 2.106367560372746e-07, 0.04932807385921478, 0.010653506964445114, 0.021004579961299896, 0.0557989627122879, -0.004361885134130716, 0.04296412691473961, -0.035218246281147, 0.0016906881937757134, -0.05059022456407547, -0.02698706090450287, -0.03994818404316902, 0.013547789305448532, -0.003925342112779617, 0.026560461148619652, 0.009953329339623451, -0.01768285408616066, 0.003640083596110344, -0.06056080758571625, -0.0008927304879762232, -0.06046701595187187, 0.003808526089414954, 0.006845757830888033, 0.08521892875432968, -0.04387311637401581, 0.009154906496405602, -0.07952504605054855, -0.012336432933807373, 0.02939177118241787, 0.03471338748931885, 0.03767586871981621, 0.011235526762902737, 0.043945763260126114, -0.0077895428985357285, -0.006909716408699751, -0.00878510344773531, -0.02934652753174305, 0.010265492834150791, -0.01814870536327362, -0.0014642311725765467, 0.14939402043819427, -0.003595777088776231, 0.016356326639652252, -0.019753264263272285, 0.0031952345743775368, 0.024177443236112595, 0.06139608472585678, -0.0035715766716748476, -0.04640227556228638, -0.022496959194540977, 0.012327955104410648, 0.00733743142336607, 0.027010101824998856, -0.052293747663497925, 0.017999986186623573, -0.020733918994665146, 0.0014685719506815076, -0.002210470149293542, -0.05263657867908478, 0.03191714361310005, -0.014937073923647404, -0.012170830741524696, -0.04265179857611656, -0.012999491766095161, 0.016117040067911148, 0.07041469216346741, 0.037697359919548035, 0.0474109947681427, 1.4858378312032037e-34, -0.010284952819347382, 0.005277789663523436, 0.014670448377728462, 0.06076040491461754, -0.026190921664237976, -0.019093884155154228, 0.031922366470098495, -0.016838911920785904, 0.04721987619996071, -0.046159710735082626, -0.017975928261876106]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.embed_query(\"Veronica is a Pythonista\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA,  ConversationalRetrievalChain\n",
    "from langchain.chains.conversational_retrieval.base import BaseConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name = \"gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "def load_db(file: str, chain_type: Literal[\"stuff\", \"map_reduce\"], k: int) -> BaseConversationalRetrievalChain:\n",
    "    # load documents\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    # split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    # define embedding\n",
    "    embeddings = SagemakerEndpointEmbeddingsJumpStart(\n",
    "        endpoint_name=\"sentence-transformers-all-mpnet-base-v2\",\n",
    "        region_name=aws_region,\n",
    "        content_handler=content_handler,\n",
    "        model_kwargs=emb_parameters,\n",
    "    )\n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0),\n",
    "        chain_type=chain_type,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    return qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got results for 77 in 95.46276664733887s, length of embeddings list is 77\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is regression',\n",
       " 'chat_history': [],\n",
       " 'answer': 'Regression is a type of supervised learning problem in machine learning. It involves predicting a continuous value or variable based on input features. In regression, the goal is to find the relationship between the input variables and the output variable in order to make accurate predictions. The term \"regression\" specifically refers to the fact that the variable being predicted is continuous.',\n",
       " 'source_documents': [Document(page_content=\"regression problem. And the term regression sort of refers to the fact that the variable \\nyou're trying to predict is a continuous value and price.  \\nThere's another class of supervised learning problems which we'll talk about, which are \\nclassification problems. And so, in a classifi cation problem, the variab le you're trying to \\npredict is discreet rather than continuous . So as one specific example — so actually a \\nstandard data set you can download online [i naudible] that lots of machine learning \\npeople have played with. Let's say you collect  a data set on breast cancer tumors, and you \\nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \\nMalignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \\nSo we collect some number of features, some  number of properties of these tumors, and \\nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're\", metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 12}),\n",
       "  Document(page_content=\"And this sort of learning pr oblem of learning to predict hous ing prices is an example of \\nwhat's called a supervised learning problem. And the reason that it's called supervised \\nlearning is because we're providing the al gorithm a data set of a bunch of square \\nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \\nactual prices of a number  of houses were, right?  \\nSo we call this supervised learning because we're supervising the algorithm or, in other \\nwords, we're giving the algorithm the, quote,  right answer for a number of houses. And \\nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \\nand to sort of give us more of the right answers, okay?  \\nIt turns out this specific exam ple that I drew here is an example of something called a \\nregression problem. And the term regression sort of refers to the fact that the variable \\nyou're trying to predict is a continuous value and price.\", metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 12})],\n",
       " 'generated_question': 'What is regression'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = load_db(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\", \"stuff\", 2)\n",
    "\n",
    "result = qa({\"question\": \"What is regression\", \"chat_history\": []})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Regression is a type of supervised learning problem in machine learning. It involves predicting a continuous value or variable based on input features. In regression, the goal is to find the relationship between the input variables and the output variable in order to make accurate predictions. The term \"regression\" specifically refers to the fact that the variable being predicted is continuous.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"regression problem. And the term regression sort of refers to the fact that the variable \\nyou're trying to predict is a continuous value and price.  \\nThere's another class of supervised learning problems which we'll talk about, which are \\nclassification problems. And so, in a classifi cation problem, the variab le you're trying to \\npredict is discreet rather than continuous . So as one specific example — so actually a \\nstandard data set you can download online [i naudible] that lots of machine learning \\npeople have played with. Let's say you collect  a data set on breast cancer tumors, and you \\nwant to learn the algorithm to predict wh ether or not a certai n tumor is malignant. \\nMalignant is the opposite of benign, right, so ma lignancy is a sort of harmful, bad tumor. \\nSo we collect some number of features, some  number of properties of these tumors, and \\nfor the sake of sort of having a simple [inaudi ble] explanation, let's just say that we're\", metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 12}),\n",
       " Document(page_content=\"And this sort of learning pr oblem of learning to predict hous ing prices is an example of \\nwhat's called a supervised learning problem. And the reason that it's called supervised \\nlearning is because we're providing the al gorithm a data set of a bunch of square \\nfootages, a bunch of housing sizes, and as well as sort of the right answer of what the \\nactual prices of a number  of houses were, right?  \\nSo we call this supervised learning because we're supervising the algorithm or, in other \\nwords, we're giving the algorithm the, quote,  right answer for a number of houses. And \\nthen we want the algorithm to learn the a ssociation between the inputs and the outputs \\nand to sort of give us more of the right answers, okay?  \\nIt turns out this specific exam ple that I drew here is an example of something called a \\nregression problem. And the term regression sort of refers to the fact that the variable \\nyou're trying to predict is a continuous value and price.\", metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 12})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param\n",
    "\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super(cbfs, self).__init__(**params)\n",
    "        self.panels = []\n",
    "        self.loaded_file = \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"\n",
    "        self.qa = load_db(self.loaded_file, \"stuff\", 4)\n",
    "\n",
    "    def call_load_db(self, count):\n",
    "        if count == 0 or file_input.value is None:  # init or no file specified :\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")  # local copy\n",
    "            self.loaded_file = file_input.filename\n",
    "            button_load.button_style = \"outline\"\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "            button_load.button_style = \"solid\"\n",
    "        self.clr_history()\n",
    "        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(\n",
    "                pn.Row(\"User:\", pn.pane.Markdown(\"\", width=600)), scroll=True\n",
    "            )\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.extend([(query, result[\"answer\"])])\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result[\"answer\"]\n",
    "        self.panels.extend(\n",
    "            [\n",
    "                pn.Row(\"User:\", pn.pane.Markdown(query, width=600)),\n",
    "                pn.Row(\n",
    "                    \"ChatBot:\",\n",
    "                    pn.pane.Markdown(\n",
    "                        self.answer, width=600, style={\"background-color\": \"#F6F6F6\"}\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        inp.value = \"\"  # clears loading indicator when cleared\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "    @param.depends(\n",
    "        \"db_query \",\n",
    "    )\n",
    "    def get_lquest(self):\n",
    "        if not self.db_query:\n",
    "            return pn.Column(\n",
    "                pn.Row(\n",
    "                    pn.pane.Markdown(\n",
    "                        f\"Last question to DB:\", styles={\"background-color\": \"#F6F6F6\"}\n",
    "                    )\n",
    "                ),\n",
    "                pn.Row(pn.pane.Str(\"no DB accesses so far\")),\n",
    "            )\n",
    "        return pn.Column(\n",
    "            pn.Row(\n",
    "                pn.pane.Markdown(f\"DB query:\", styles={\"background-color\": \"#F6F6F6\"})\n",
    "            ),\n",
    "            pn.pane.Str(self.db_query),\n",
    "        )\n",
    "\n",
    "    @param.depends(\n",
    "        \"db_response\",\n",
    "    )\n",
    "    def get_sources(self):\n",
    "        if not self.db_response:\n",
    "            return\n",
    "        rlist = [\n",
    "            pn.Row(\n",
    "                pn.pane.Markdown(\n",
    "                    f\"Result of DB lookup:\", styles={\"background-color\": \"#F6F6F6\"}\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        for doc in self.db_response:\n",
    "            rlist.append(pn.Row(pn.pane.Str(doc)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    @param.depends(\"convchain\", \"clr_history\")\n",
    "    def get_chats(self):\n",
    "        if not self.chat_history:\n",
    "            return pn.WidgetBox(\n",
    "                pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True\n",
    "            )\n",
    "        rlist = [\n",
    "            pn.Row(\n",
    "                pn.pane.Markdown(\n",
    "                    f\"Current Chat History variable\",\n",
    "                    styles={\"background-color\": \"#F6F6F6\"},\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        for exchange in self.chat_history:\n",
    "            rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    def clr_history(self, count=0):\n",
    "        self.chat_history = []\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got results for 77 in 96.36150693893433s, length of embeddings list is 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:param.Column00323: Displaying Panel objects in the notebook requires the panel extension to be loaded. Ensure you run pn.extension() before displaying objects in the notebook.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Column\n",
       "    [0] Row\n",
       "        [0] Markdown(str)\n",
       "    [1] Tabs\n",
       "        [0] Column\n",
       "            [0] Row\n",
       "                [0] TextInput(placeholder='Enter text here…')\n",
       "            [1] Divider()\n",
       "            [2] ParamFunction(function, _pane=WidgetBox, defer_load=False, height=300, loading_indicator=True)\n",
       "            [3] Divider()\n",
       "        [1] Column\n",
       "            [0] ParamMethod(method, _pane=Column, defer_load=False)\n",
       "            [1] Divider()\n",
       "            [2] ParamMethod(method, _pane=Str, defer_load=False)\n",
       "        [2] Column\n",
       "            [0] ParamMethod(method, _pane=WidgetBox, defer_load=False)\n",
       "            [1] Divider()\n",
       "        [3] Column\n",
       "            [0] Row\n",
       "                [0] FileInput(accept='.pdf')\n",
       "                [1] Button(button_type='primary', name='Load DB')\n",
       "                [2] ParamFunction(function, _pane=Markdown, defer_load=False)\n",
       "            [1] Row\n",
       "                [0] Button(button_type='warning', name='Clear History')\n",
       "                [1] Markdown(str)\n",
       "            [2] Divider()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb = cbfs()\n",
    "\n",
    "file_input = pn.widgets.FileInput(accept=\".pdf\")\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type=\"primary\")\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type=\"warning\")\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput(placeholder=\"Enter text here…\")\n",
    "\n",
    "bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
    "conversation = pn.bind(cb.convchain, inp)\n",
    "\n",
    "# jpg_pane = pn.pane.Image(\"./img/convchain.jpg\")\n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation, loading_indicator=True, height=300),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab2 = pn.Column(\n",
    "    pn.panel(cb.get_lquest),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(cb.get_sources),\n",
    ")\n",
    "tab3 = pn.Column(\n",
    "    pn.panel(cb.get_chats),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab4 = pn.Column(\n",
    "    pn.Row(file_input, button_load, bound_button_load),\n",
    "    pn.Row(\n",
    "        button_clearhistory,\n",
    "        pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\"),\n",
    "    ),\n",
    "    pn.layout.Divider(),\n",
    "    # pn.Row(jpg_pane.clone(width=400)),\n",
    ")\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown(\"# ChatWithYourData_Bot\")),\n",
    "    pn.Tabs(\n",
    "        (\"Conversation\", tab1),\n",
    "        (\"Database\", tab2),\n",
    "        (\"Chat History\", tab3),\n",
    "        (\"Configure\", tab4),\n",
    "    ),\n",
    ")\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
