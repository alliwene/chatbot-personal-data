{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Falcon-7b-instruct Sagemaker Endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "import boto3\n",
    "from langchain import PromptTemplate, SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandlerLLM(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({'inputs': prompt, 'parameters': model_kwargs})\n",
    "        return input_str.encode('utf-8')\n",
    "      \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))        \n",
    "        return response_json[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"falcon-7b-instruct\"\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"max_new_tokens\": 300,\n",
    "    \"return_full_text\": False,\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.3,\n",
    "}\n",
    "\n",
    "content_handler = ContentHandlerLLM()\n",
    "\n",
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    region_name=aws_region,\n",
    "    model_kwargs=parameters,\n",
    "    content_handler=content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' on Earth?\\nThe largest mammal on Earth is the blue whale.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"What is the largest mammal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Sagemaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import json\n",
    "\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SagemakerEndpointEmbeddingsJumpStart` [Source](https://medium.com/@ryanntk/deploying-hugging-face-embedding-models-on-aws-sagemaker-a-comprehensive-tutorial-with-langchain-af8e0b405b51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# extend the SagemakerEndpointEmbeddings class from langchain to provide a custom embedding function\n",
    "class SagemakerEndpointEmbeddingsJumpStart(SagemakerEndpointEmbeddings):\n",
    "    def embed_documents(\n",
    "        self, texts: List[str], chunk_size: int = 5\n",
    "    ) -> List[List[float]]:\n",
    "        \"\"\"Compute doc embeddings using a SageMaker Inference Endpoint.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "            chunk_size: The chunk size defines how many input texts will\n",
    "                be grouped together as request. If None, will use the\n",
    "                chunk size specified by the class.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        _chunk_size = len(texts) if chunk_size > len(texts) else chunk_size\n",
    "        st = time.time()\n",
    "        for i in range(0, len(texts), _chunk_size):\n",
    "            response = self._embedding_func(texts[i : i + _chunk_size])\n",
    "            results.extend(response)\n",
    "        time_taken = time.time() - st\n",
    "        print(\n",
    "            f\"got results for {len(texts)} in {time_taken}s, length of embeddings list is {len(results)}\"\n",
    "        )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandler(EmbeddingsContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, inputs: list[str], model_kwargs: Dict) -> bytes:\n",
    "        \"\"\"\n",
    "        Transforms the input into bytes that can be consumed by SageMaker endpoint.\n",
    "        Args:\n",
    "            inputs: List of input strings.\n",
    "            model_kwargs: Additional keyword arguments to be passed to the endpoint.\n",
    "        Returns:\n",
    "            The transformed bytes input.\n",
    "        \"\"\"\n",
    "        # Example: inference.py expects a JSON string with a \"inputs\" key:\n",
    "        # input_str = json.dumps({\"inputs\": inputs, **model_kwargs})\n",
    "        input_str = json.dumps({\"inputs\": inputs, \"parameters\": model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Transforms the bytes output from the endpoint into a list of embeddings.\n",
    "        Args:\n",
    "            output: The bytes output from SageMaker endpoint.\n",
    "        Returns:\n",
    "            The transformed output - list of embeddings\n",
    "        Note:\n",
    "            The length of the outer list is the number of input strings.\n",
    "            The length of the inner lists is the embedding dimension.\n",
    "        \"\"\"\n",
    "        # Example: inference.py returns a JSON string with the list of\n",
    "        # embeddings in a \"vectors\" key:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[\"vectors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_handler = ContentHandler()\n",
    "\n",
    "emb_parameters = {\"device\": \"cuda\"}\n",
    "\n",
    "embeddings = SagemakerEndpointEmbeddingsJumpStart(\n",
    "    # credentials_profile_name=\"credentials-profile-name\",\n",
    "    endpoint_name=\"sentence-transformers-all-mpnet-base-v2\",\n",
    "    region_name=aws_region,\n",
    "    content_handler=content_handler,\n",
    "    model_kwargs=emb_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_query(\"foo bar dog\")\n",
    "len(query_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got results for 2 in 0.8022239208221436s, length of embeddings list is 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result = embeddings.embed_documents([\"foo bar dog\", \"Veronica is a Pythonista\"])\n",
    "len(query_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.023010829463601112, 0.06674211472272873, 0.015658535063266754, -0.059901751577854156, 0.00899288710206747, 0.04786750301718712, 0.005673463921993971, 0.023586349561810493, -0.06605415046215057, 0.02126981131732464, -0.0002889889001380652, 0.03975634276866913, -0.03429273143410683, 0.05184069275856018, 0.02275446429848671, -0.01708190329372883, 0.017952624708414078, 0.03652235493063927, 0.07056411355733871, -0.040407828986644745, -0.00187441217713058, 0.02352127991616726, 0.004665896762162447, 0.018560048192739487, -0.047574300318956375, 0.002585913985967636, -0.018474262207746506, -0.003118740627542138, -0.06551744788885117, -0.013685131445527077, -0.04172193631529808, 0.01329813152551651, -0.017570368945598602, 0.003636210458353162, 2.1068485693831462e-06, -0.01581939496099949, -0.01604585535824299, 0.005425119306892157, 0.0680365040898323, -0.05921432375907898, -0.08718516677618027, -0.020225796848535538, -0.02191966399550438, 0.006423304323107004, -0.029958896338939667, -0.06446627527475357, 0.027559543028473854, 0.05543999373912811, -0.028078239411115646, 0.05419043079018593, 0.0026187326293438673, -0.06932499259710312, -0.04494498670101166, -0.006852503400295973, 0.06747487187385559, -0.030603639781475067, -0.015401860699057579, 0.03245040401816368, -0.02740316651761532, 0.01179177314043045, -0.004053470212966204, -0.01009947806596756, 0.0403747633099556, -0.01324413251131773, -0.02347446233034134, 0.03465811908245087, -0.07925324887037277, 0.04883779212832451, -0.01725759170949459, 0.018148820847272873, -0.028094980865716934, -0.03544998541474342, -0.017630720511078835, 0.06869210302829742, 0.03419966250658035, -0.06409057974815369, -0.0016255058581009507, 0.014894452877342701, 0.04303397610783577, 0.016619134694337845, -0.0655159205198288, -0.026041580364108086, 0.011132064275443554, 0.02523624338209629, -0.039060771465301514, 0.06385379284620285, -0.02139345556497574, -0.007874553091824055, 0.005833492614328861, 0.05675233528017998, -0.010215059854090214, 0.015196838416159153, 0.023410920053720474, 0.049527719616889954, -0.01400525402277708, 0.007330155000090599, -0.027285123243927956, 0.006774749141186476, -0.009495573118329048, 0.03008597530424595, 0.006717353127896786, 0.0014923124108463526, 0.00787079893052578, 0.04534438997507095, 0.0031724045984447002, 0.02922164462506771, -0.01954904943704605, -0.029319165274500847, 0.02546115778386593, -0.05150489881634712, -0.07623180747032166, -0.009595748037099838, -0.010187103413045406, 0.0419883131980896, 0.03391626849770546, -0.02373092621564865, 0.0013637612573802471, 0.022877639159560204, 0.00831610057502985, 0.010663634166121483, -0.013551000505685806, -0.011806602589786053, 0.02341092750430107, 0.07065224647521973, 0.04271245747804642, 0.005824619438499212, -0.10125032067298889, 0.054022956639528275, 0.006044263485819101, 0.01107492670416832, 0.007341252639889717, 0.03353413566946983, -0.06093713268637657, -0.027571193873882294, 0.016989216208457947, -0.005499851889908314, -0.0069758277386426926, -0.01142292283475399, -0.0018827557796612382, -0.012339175678789616, -0.07685516774654388, -0.04822944477200508, 0.004893387667834759, -0.04497228562831879, 0.007427186705172062, -0.031675372272729874, -0.0013049524277448654, 0.03579952195286751, -0.03668150305747986, -0.013009931892156601, 0.015499680303037167, 0.007876859977841377, -0.08967886120080948, -0.010298510082066059, -0.00795599166303873, 0.02673277072608471, -0.057854581624269485, -0.03302031382918358, 0.010414022020995617, 0.0010603995760902762, 0.005370123777538538, 0.002366454340517521, -0.044107601046562195, -0.013039017096161842, 0.003458276391029358, -0.03264845535159111, -0.010508754290640354, -0.00835302472114563, 0.004713899921625853, -0.04510847106575966, -0.012755651958286762, 0.01692296750843525, 0.030524250119924545, 0.03768853098154068, 0.035064708441495895, 0.05048993602395058, 0.02682623639702797, 0.017809994518756866, -0.030583703890442848, -0.04651307314634323, 0.030226953327655792, -0.03472358360886574, 0.014279928989708424, 0.001994319027289748, -0.07616851478815079, -0.021231915801763535, 0.041119519621133804, 0.023551054298877716, -0.02902073785662651, -0.02129901573061943, 0.0398409366607666, 0.004537781234830618, 0.023622728884220123, 0.03720119595527649, 0.015066093765199184, 0.014487423934042454, 0.0025482350029051304, -0.1087401732802391, 0.005506589543074369, 0.020443687215447426, -0.05446306988596916, 0.048238396644592285, 0.026937145739793777, -0.0003474353579804301, 0.011624503880739212, 0.020883390679955482, 0.06968170404434204, -0.021589716896414757, 0.009883466176688671, 0.013504407368600368, 0.007010550703853369, -0.005145477131009102, 0.01859726570546627, 0.06254380941390991, -0.008416026830673218, 0.051103487610816956, 0.012462976388633251, -0.0014173596864566207, 0.049751847982406616, 0.06316088140010834, -0.01048077642917633, 0.04253240302205086, -0.019946375861763954, 0.01848849654197693, 0.10847096145153046, -0.031477123498916626, 0.0014083576388657093, -0.017507240176200867, 0.045508984476327896, 0.005288006272166967, -0.01992693357169628, -0.012253225781023502, 0.05077618733048439, 0.031070396304130554, 0.03807516768574715, -0.01251057256013155, 0.0337238647043705, -0.004974474664777517, 0.010957763530313969, 0.03183368593454361, 0.020739996805787086, 0.03824857249855995, -0.007297822739928961, 0.0013917008182033896, 0.07464830577373505, 0.007142022717744112, 0.08202540874481201, -0.008178972639143467, -0.003124932525679469, -0.019090555608272552, -0.022937530651688576, -0.026072589680552483, -0.004665476270020008, -0.02244298905134201, 0.03574899211525917, -0.0337204672396183, 0.0674581378698349, 0.004455369897186756, -0.0013021505437791348, -0.021021761000156403, 0.1279732584953308, -0.006083676125854254, 0.0007607946172356606, 0.038103315979242325, 0.015111555345356464, -0.0037356307730078697, -0.028185483068227768, -0.03302307426929474, -0.012463519349694252, -0.011571018025279045, 0.04976337403059006, 0.019924204796552658, -0.004556228872388601, 0.022879982367157936, -0.05274885147809982, -0.019249511882662773, 0.00212375121191144, -0.045621905475854874, -0.010462688282132149, -0.0036699266638606787, 0.03641803190112114, 0.034517351537942886, 0.01942635513842106, 0.02007974684238434, -0.01511363685131073, -0.0463373176753521, -0.012162714265286922, 0.0020720127504318953, -0.03927887603640556, -0.020818596705794334, -0.042365141212940216, -0.018530000001192093, 0.03966914862394333, -0.017651056870818138, 0.025569723919034004, 0.03735378757119179, 0.02802629955112934, -0.05534663423895836, 0.024187644943594933, 0.015183375217020512, 0.03360293060541153, 0.04908657446503639, 0.008308899588882923, -0.025269975885748863, 0.016446353867650032, -0.007383799646049738, -0.039706017822027206, 0.024582283571362495, 0.03308204934000969, -0.03622559458017349, 0.043494582176208496, 0.0015286939451470971, -0.028200285509228706, 0.0863780602812767, 0.014692171476781368, -0.05767326056957245, -0.05677102878689766, -0.055296946316957474, -0.02605327032506466, 0.012740252539515495, 0.02138972096145153, 0.005055899266153574, 2.5503759388811886e-05, -0.019994748756289482, -0.010931555181741714, 0.03636316582560539, -0.055819783359766006, 0.01594778522849083, 0.05470077320933342, -0.010836183093488216, 0.023871170356869698, 0.08289739489555359, 0.005749847274273634, -0.02573838084936142, 0.011421150527894497, -0.04512236267328262, -0.011098035611212254, -0.06551823765039444, 0.007781904190778732, 0.03390177711844444, 0.027678584679961205, 0.008255341090261936, -0.014465789310634136, -0.03405260294675827, -0.04136351868510246, 0.015928974375128746, -0.13232514262199402, -0.014237525872886181, -0.04330163449048996, -0.03351152688264847, -0.004496952053159475, -0.031220128759741783, 0.010743004269897938, -0.02696734480559826, 0.0033131353557109833, 0.037518925964832306, 0.023038649931550026, -0.019067568704485893, 0.007505213841795921, 0.026823237538337708, -0.08967205137014389, 0.0011069491738453507, 0.05954236164689064, -0.004369743168354034, -0.033817000687122345, 0.038619786500930786, 0.013515312224626541, 0.0023591218050569296, -0.013474767096340656, 0.015064521692693233, -0.035000432282686234, -0.007012957241386175, 0.020978230983018875, 0.08536477386951447, -0.007563481107354164, 0.06456395983695984, 0.04707031697034836, 0.018174339085817337, 0.045861173421144485, -0.027728598564863205, 0.06230560690164566, -0.09495425969362259, -0.024466896429657936, 0.004062929656356573, -0.020227771252393723, -0.007179840002208948, 0.051411114633083344, -0.02549796737730503, -0.05659577623009682, 0.01716974750161171, 0.033926818519830704, -0.04299122467637062, -0.05843474343419075, 0.0066446540877223015, -0.00794366654008627, -0.012367756105959415, -0.05391916632652283, -0.00024091439263429493, -0.003016125177964568, 0.020995721220970154, -0.020286129787564278, 0.14206643402576447, 0.025578737258911133, 0.02990243397653103, 0.004624832887202501, 0.008555535227060318, 0.07362736761569977, -0.007198780309408903, 0.0008469286258332431, 0.049492139369249344, -0.034237056970596313, -0.10526195168495178, 0.017486561089754105, -0.013994946144521236, -0.03264278545975685, -0.033486008644104004, 0.012874714098870754, -0.019406288862228394, -0.02978390082716942, -0.03531445935368538, 0.031493593007326126, -0.02057923749089241, -0.02754892036318779, -0.01977190561592579, -0.055223383009433746, -0.00915698241442442, 0.031369246542453766, 5.041166514274664e-05, 0.06581266224384308, 0.005811075679957867, 0.004947269801050425, -0.010235033929347992, -0.006612847093492746, -0.0666307583451271, 0.03872339800000191, -0.07772387564182281, -0.010483360849320889, -0.0407271534204483, -0.08086185902357101, -0.042168840765953064, -0.02000986412167549, 0.0040548089891672134, -0.020952513441443443, -0.044977884739637375, 0.06145330145955086, -0.09113430976867676, -0.004462599754333496, 0.022423872724175453, 0.03445257991552353, -0.006614299025386572, 0.008550687693059444, -0.061580006033182144, -0.053340718150138855, -0.017241502180695534, 0.08175063878297806, -0.011567949317395687, 0.03487201780080795, 0.06383499503135681, -0.01461495365947485, 0.019816551357507706, 0.07007011026144028, 0.023461509495973587, 0.0015498349675908685, -0.039492007344961166, 0.061980392783880234, -0.006202668882906437, -0.0521758496761322, -0.0032829332631081343, 0.022535966709256172, -0.01106068305671215, -0.06306261569261551, 0.009892704896628857, -0.018681492656469345, 0.0032396765891462564, 0.023204542696475983, -0.009349946863949299, 0.005748561583459377, -0.11012148857116699, -0.0627870112657547, 0.024547163397073746, 0.01729448325932026, -0.025977447628974915, -0.014056234620511532, -0.05644175410270691, 0.011549227871000767, 0.019201824441552162, 0.003449459793046117, -0.01110924407839775, -0.02803686633706093, -0.05116214603185654, -0.0037593026645481586, -0.022287728264927864, -0.009074483998119831, -0.04227137938141823, -0.020952653139829636, 0.023293308913707733, -0.07390297949314117, -0.03696122020483017, 0.012173552997410297, 0.006799119058996439, 0.015167376957833767, 0.004703959915786982, -0.0008468967862427235, 0.06477215886116028, -0.0013019004836678505, 0.01633444055914879, -0.006077290046960115, -0.00752828735858202, -0.012115146033465862, -0.04492707550525665, 0.004496962297707796, -0.002900796476751566, -0.0778275653719902, -0.01946399360895157, 0.004633028991520405, -0.016914010047912598, -0.02397526241838932, -0.0216082651168108, 0.01028000470250845, -0.013051548041403294, -0.0007539827493019402, -0.02092389203608036, 0.008950836956501007, -0.017262734472751617, 0.018538203090429306, -0.05445658415555954, 0.016340481117367744, -0.0012404675362631679, 0.019093187525868416, 0.04756149277091026, 0.04087996110320091, 0.03385937213897705, 0.01503147091716528, 0.02589898183941841, 0.004808834753930569, 0.03551849350333214, 0.08423428982496262, 0.07739220559597015, -0.028364337980747223, 0.03009629249572754, -0.007325999438762665, 0.002759980270639062, -0.011097123846411705, -0.03555351123213768, 0.07339684665203094, 0.04047708213329315, 0.027645396068692207, 0.057102106511592865, -0.03865982964634895, 0.03840562701225281, -0.021623192355036736, 0.0070581817999482155, 0.025119509547948837, -0.02347157895565033, -0.07514849305152893, -7.569902970019273e-33, -0.01588786207139492, -0.061238691210746765, 0.020396197214722633, -0.003003151388838887, -0.09604564309120178, -0.0395798534154892, -0.04936326667666435, 0.0066701616160571575, -0.02741643600165844, 0.0018353798659518361, -0.039583250880241394, -0.0009279444930143654, 0.013477861881256104, -0.03961499407887459, 0.05652448907494545, -0.0036940716672688723, 0.01730922795832157, 0.01177230291068554, -0.012265512719750404, -0.02759370394051075, 0.05455484986305237, 0.029589680954813957, -0.0007720024441368878, -0.04620949551463127, -0.029540466144680977, 0.05297929793596268, -0.07141607999801636, -0.04870860278606415, 0.03284231945872307, -0.014889433048665524, 0.02743079699575901, 0.0251883864402771, 0.011688550002872944, 0.04583723470568657, -0.009786230511963367, -0.022422121837735176, -0.037831224501132965, 0.005389497149735689, 0.04308728501200676, -0.013435769826173782, -0.00951867550611496, 0.004762003198266029, -0.032099418342113495, -0.0659119188785553, -0.014647260308265686, 0.001734729390591383, 0.014078889042139053, -0.03751515969634056, 0.005206228233873844, -0.040992867201566696, -0.05830736458301544, -0.01646733656525612, -0.027035633102059364, -0.02279207855463028, -0.002234056359156966, 0.030421718955039978, -0.013256027363240719, 0.005003741942346096, 0.03847838193178177, 0.01069438923150301, 0.04410755634307861, -0.015559962950646877, 0.013862493447959423, -0.04908732697367668, 0.023104585707187653, 0.033264875411987305, 0.04234946519136429, -0.03861241415143013, 0.029563581570982933, -0.03540949895977974, -0.009775746613740921, 0.007092204876244068, 0.019781410694122314, -0.05743137374520302, 0.05902979522943497, -0.04011101275682449, -0.017601270228624344, -0.04833642765879631, 0.08239274471998215, -0.0011447558645159006, -0.0472562238574028, 0.009285803884267807, 0.02023926191031933, 0.027294063940644264, 0.0012926597846671939, 0.03217925876379013, 0.027979955077171326, -0.04386712610721588, -0.022133518010377884, -0.00828301440924406, -0.05244899541139603, -0.026424620300531387, 0.0025984004605561495, 0.013857136480510235, 0.05617096275091171, -0.005231060553342104, -0.03087419457733631, -0.011859399266541004, 0.003875053022056818, -0.017136525362730026, 0.03928801789879799, -0.02477360889315605, 0.03139757737517357, 0.013883163221180439, 0.023625517264008522, 0.020689401775598526, 0.11114655435085297, -0.0038666129112243652, -0.011141984723508358, -0.01970728673040867, 0.011199412867426872, 0.01358599029481411, 0.031070029363036156, 0.048436325043439865, 0.034643497318029404, 0.0362677164375782, 0.004830552730709314, -0.0014726048102602363, -0.006835830397903919, 0.031388066709041595, 0.025326021015644073, 0.017306936904788017, -0.05484793707728386, 0.01671455428004265, -0.03740868717432022, 0.00724161509424448, -0.011899317614734173, 0.0361383892595768, 0.028325920924544334, 0.018300481140613556, -0.011571473442018032, 0.008201267570257187, 2.7858814632963913e-07, 0.03414873778820038, -0.016037501394748688, 0.013661477714776993, 0.07834918797016144, 0.01870156265795231, 0.0047751120291650295, -0.025973642244935036, 0.00555970286950469, -0.02857847884297371, -0.00647660531103611, 0.001415227190591395, -0.014073582366108894, 0.009553872048854828, -0.02112840674817562, 0.008032886311411858, 0.07710931450128555, -0.031797830015420914, -0.03137623146176338, 0.006319756619632244, 0.005778934340924025, -0.03378457576036453, 0.022292660549283028, 0.024898257106542587, -0.020262636244297028, -0.007175086066126823, -0.01032057125121355, -0.023920347914099693, 0.029783012345433235, 0.05430519953370094, -0.043410759419202805, -0.06804252415895462, 0.05560963600873947, -0.02781541831791401, -0.03115813061594963, -0.026592452079057693, -0.02775963582098484, -0.023671235889196396, 0.04942530766129494, 0.015187922865152359, 0.03165620192885399, -0.030071092769503593, 0.013661907985806465, -0.010235030204057693, 0.04684643819928169, 0.03315334394574165, -0.010108760558068752, -0.0008697279845364392, 0.06759144365787506, -0.04992649704217911, -0.02201100066304207, -0.00654872041195631, -0.05754455178976059, 0.02960176207125187, 0.017233718186616898, 0.00449666753411293, -0.0016306889010593295, 0.05527477711439133, 0.00944055151194334, -0.007946529425680637, 0.0017343375366181135, 0.015063010156154633, 0.012958833947777748, 0.010433575138449669, 0.012985926121473312, -0.01247435063123703, -0.1099582090973854, -0.02212277054786682, 2.022774148505684e-34, 0.0023825266398489475, 0.006947158370167017, 0.039792224764823914, 0.055848535150289536, -0.03635522723197937, 0.013340016826987267, -0.08889389783143997, -0.021237820386886597, 0.024268873035907745, -0.0004453130823094398, -0.0018311935709789395]\n"
     ]
    }
   ],
   "source": [
    "print(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![steps](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  6.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loader = DirectoryLoader(\n",
    "#     \"docs/cs229_lectures/\", glob=\"**/*.pdf\", show_progress=True, loader_cls=PyPDFLoader\n",
    "# )\n",
    "# pages = loader.load()\n",
    "# len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\n",
    "    \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\",\n",
    ")\n",
    "pages = loader.load() \n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = text_splitter.split_documents(pages)\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store and Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "persist_directory = \"docs/chromahf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    }
   ],
   "source": [
    "# vectordb = Chroma.from_documents(\n",
    "#     documents=splits, embedding=embeddings, persist_directory=persist_directory\n",
    "# )\n",
    "\n",
    "vectordb = Chroma(embedding_function=embeddings, persist_directory=persist_directory)\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"So later this quarter, we'll use the discussion sections to talk about things like convex \\noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \\nlearning algorithm for modeling time series and a few other things, so  extensions to the \\nmaterials that I'll be covering in the main  lectures. And attend ance at the discussion \\nsections is optional, okay?  \\nSo that was all I had from l ogistics. Before we move on to start talking a bit about \\nmachine learning, let me check what questions you have. Yeah?  \\nStudent : [Inaudible] R or something like that?  \\nInstructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \\nwelcome to use R, but I would strongly advi se against it, mainly because in the last \\nproblem set, we actually supply some code th at will run in Octave  but that would be \\nsomewhat painful for you to translate into R yourself. So for your other assignments, if \\nyou wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \\nworth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \\nbit more often for various reasons. Yeah?  \\nStudent : For the [inaudible] pr oject [inaudible]?  \\nInstructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \\ngroups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \\nsame regardless of the group size, so with  a larger group, you probably — I recommend\", metadata={'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content='into his office and he said, \"Oh, professo r, professor, thank you so much for your \\nmachine learning class. I learned so much from it. There\\'s this stuff that I learned in your \\nclass, and I now use every day. And it\\'s help ed me make lots of money, and here\\'s a \\npicture of my big house.\"  \\nSo my friend was very excited. He said, \"W ow. That\\'s great. I\\'m glad to hear this \\nmachine learning stuff was actually useful. So what was it that you learned? Was it \\nlogistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \\nlearned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \\nSo for those of you that don\\'t know MATLAB yet, I hope you do learn it. It\\'s not hard, \\nand we\\'ll actually have a short MATLAB tutori al in one of the discussion sections for \\nthose of you that don\\'t know it.  \\nOkay. The very last piece of logistical th ing is the discussion s ections. So discussion \\nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \\nalthough they\\'ll also be recorded and televi sed. And we\\'ll use the discussion sections \\nmainly for two things. For the next two or th ree weeks, we\\'ll use the discussion sections \\nto go over the prerequisites to this class or if some of you haven\\'t seen probability or \\nstatistics for a while or maybe algebra, we\\'ll go over those in the discussion sections as a \\nrefresher for those of you that want one.', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content=\"person's face physically attractive. There's a learning algorithm on op tical illusions, and \\nso on.  \\nAnd it goes on, so lots of fun projects. A nd take a look, then come up with your own \\nideas. But whatever you find cool and interest ing, I hope you'll be able to make machine \\nlearning a project out of it. Yeah, question?  \\nStudent : Are these gro up projects?  \\nInstructor (Andrew Ng): Oh, yes, thank you.  \\nStudent : So how many people can be in a group?  \\nInstructor (Andrew Ng): Right. So projects can be done in  groups of up to three people. \\nSo as part of forming study groups, later t oday as you get to know your classmates, I \\ndefinitely also encourage you to grab two ot her people and form a group of up to three \\npeople for your project, okay? And just start brainstorming ideas for now amongst \\nyourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \\nwith us.  \\nOkay. So one more organizational ques tion. I'm curious, how many of you know \\nMATLAB? Wow, cool, quite a lot. Okay. So as part of the — act ually how many of you \\nknow Octave or have used Octave ? Oh, okay, much smaller number.  \\nSo as part of this class, especially in the homeworks, we'll ask you to implement a few \\nprograms, a few machine learning algorithms as  part of the homeworks. And most of\", metadata={'page': 7, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.similarity_search(\"what did they say about matlab?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs: List[Document]) -> None:\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def get_metadata(docs: List[Document]) -> None:\n",
    "    for doc in docs:\n",
    "        print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"So later this quarter, we'll use the discussion sections to talk about things like convex \\noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \\nlearning algorithm for modeling time series and a few other things, so  extensions to the \\nmaterials that I'll be covering in the main  lectures. And attend ance at the discussion \\nsections is optional, okay?  \\nSo that was all I had from l ogistics. Before we move on to start talking a bit about \\nmachine learning, let me check what questions you have. Yeah?  \\nStudent : [Inaudible] R or something like that?  \\nInstructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \\nwelcome to use R, but I would strongly advi se against it, mainly because in the last \\nproblem set, we actually supply some code th at will run in Octave  but that would be \\nsomewhat painful for you to translate into R yourself. So for your other assignments, if \\nyou wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \\nworth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \\nbit more often for various reasons. Yeah?  \\nStudent : For the [inaudible] pr oject [inaudible]?  \\nInstructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \\ngroups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \\nsame regardless of the group size, so with  a larger group, you probably — I recommend\", metadata={'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}), Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "docs = vectordb.max_marginal_relevance_search(question, k=2, fetch_k=3)\n",
    "print(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "get_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \n",
      "without even knowing it.  \n",
      "And of course, learning algorithms are also  doing things like giving us a growing \n",
      "understanding of the human genome. So if so meday we ever find a cure for cancer, I bet \n",
      "learning algorithms will have had a large role in that. That's sort of the thing that Tom \n",
      "works on, yes?  \n",
      "So in teaching this class, I sort of have thre e goals. One of them is just to I hope convey \n",
      "some of my own excitement a bout machine learning to you.  \n",
      "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\n",
      "the-art machine learning algorithms to whatev er problems you're interested in. And if you \n",
      "ever need to build a system for reading zi p codes, you'll know how to do that by the end \n",
      "of this class.  \n",
      "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \n",
      "doing research in machine learning, but by the c onclusion of this class,  I hope that all of \n",
      "you will actually be well qualified to star t doing research in machine learning, okay?  \n",
      "So let's say a few words about logistics. The prerequisites of this class are written on one \n",
      "of the handouts, are as follows: In this class, I'm going to assume that all of you have sort \n",
      "of basic knowledge of computer science and kn owledge of the basic computer skills and \n",
      "principles. So I assume all of you know what big?O notation, that all of you know about\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Similarly, every time you write a check, I ac tually don't know the number for this, but a \n",
      "significant fraction of checks that you write are processed by a learning algorithm that's \n",
      "learned to read the digits, so the dolla r amount that you wrote down on your check. So \n",
      "every time you write a check, there's anot her learning algorithm that you're probably \n",
      "using without even being aware of it.  \n",
      "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \n",
      "companies like eBay as well that do electr onic transactions, there's a good chance that \n",
      "there's a learning algorithm in the backgr ound trying to figure out if, say, your credit \n",
      "card's been stolen or if someone's engaging in a fraudulent transaction.  \n",
      "If you use a website like Amazon or Netflix that will often recommend books for you to \n",
      "buy or movies for you to rent or whatever , these are other examples of learning \n",
      "algorithms that have learned what sorts of th ings you like to buy or what sorts of movies \n",
      "you like to watch and can therefore give  customized recommendations to you.  \n",
      "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \n",
      "to explain to me some learning algorithm in th e innards of my car th at's sort of doing its \n",
      "best to optimize my driving performan ce for fuel efficiency or something.  \n",
      "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \n",
      "without even knowing it.\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression on page 3?\"\n",
    "\n",
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=2,\n",
    "    filter={\"page\": 3},\n",
    ")\n",
    "\n",
    "pretty_print_docs(docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "get_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Self-Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    # AttributeInfo(\n",
    "    #     name=\"source\",\n",
    "    #     description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "    #     type=\"string\",\n",
    "    # ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "base_llm = OpenAI(temperature=0)\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    base_llm, vectordb, document_content_description, metadata_field_info, verbose=True\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alli/miniconda3/envs/openai/lib/python3.11/site-packages/langchain/chains/llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='regression' filter=Comparison(comparator=<Comparator.EQ: 'eq'>, attribute='page', value=3) limit=None\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about regression on page 3?\"\n",
    "\n",
    "docs = retriever.get_relevant_documents(question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \n",
      "without even knowing it.  \n",
      "And of course, learning algorithms are also  doing things like giving us a growing \n",
      "understanding of the human genome. So if so meday we ever find a cure for cancer, I bet \n",
      "learning algorithms will have had a large role in that. That's sort of the thing that Tom \n",
      "works on, yes?  \n",
      "So in teaching this class, I sort of have thre e goals. One of them is just to I hope convey \n",
      "some of my own excitement a bout machine learning to you.  \n",
      "The second goal is by the end of this class, I hope all of you will be ab le to apply state-of-\n",
      "the-art machine learning algorithms to whatev er problems you're interested in. And if you \n",
      "ever need to build a system for reading zi p codes, you'll know how to do that by the end \n",
      "of this class.  \n",
      "And lastly, by the end of this class, I reali ze that only a subset of  you are interested in \n",
      "doing research in machine learning, but by the c onclusion of this class,  I hope that all of \n",
      "you will actually be well qualified to star t doing research in machine learning, okay?  \n",
      "So let's say a few words about logistics. The prerequisites of this class are written on one \n",
      "of the handouts, are as follows: In this class, I'm going to assume that all of you have sort \n",
      "of basic knowledge of computer science and kn owledge of the basic computer skills and \n",
      "principles. So I assume all of you know what big?O notation, that all of you know about\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "Similarly, every time you write a check, I ac tually don't know the number for this, but a \n",
      "significant fraction of checks that you write are processed by a learning algorithm that's \n",
      "learned to read the digits, so the dolla r amount that you wrote down on your check. So \n",
      "every time you write a check, there's anot her learning algorithm that you're probably \n",
      "using without even being aware of it.  \n",
      "If you use a credit card, or I know at least one phone compan y was doing this, and lots of \n",
      "companies like eBay as well that do electr onic transactions, there's a good chance that \n",
      "there's a learning algorithm in the backgr ound trying to figure out if, say, your credit \n",
      "card's been stolen or if someone's engaging in a fraudulent transaction.  \n",
      "If you use a website like Amazon or Netflix that will often recommend books for you to \n",
      "buy or movies for you to rent or whatever , these are other examples of learning \n",
      "algorithms that have learned what sorts of th ings you like to buy or what sorts of movies \n",
      "you like to watch and can therefore give  customized recommendations to you.  \n",
      "Just about a week ago, I had my car serviced, and even there, my car mechanic was trying \n",
      "to explain to me some learning algorithm in th e innards of my car th at's sort of doing its \n",
      "best to optimize my driving performan ce for fuel efficiency or something.  \n",
      "So, see, most of us use learning algorithms half a dozen, a dozen, maybe dozens of times \n",
      "without even knowing it.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "principles. So I assume all of you know what big?O notation, that all of you know about \n",
      "sort of data structures like  queues, stacks, binary trees , and that all of you know enough \n",
      "programming skills to, like, write a simple co mputer program. And it turns out that most\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 3, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "get_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alli/miniconda3/envs/openai/lib/python3.11/site-packages/langchain/chains/llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query='regression' filter=Operation(operator=<Operator.AND: 'and'>, arguments=[Comparison(comparator=<Comparator.GTE: 'gte'>, attribute='page', value=1), Comparison(comparator=<Comparator.LTE: 'lte'>, attribute='page', value=10)]) limit=None\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 6, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 7, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 10, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "question = (\n",
    "    \"what did they say about regression between pages one and ten?\"\n",
    ")\n",
    "\n",
    "docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "get_metadata(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_llm = OpenAI(temperature=0)\n",
    "compressor = LLMChainExtractor.from_llm(base_llm)\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "\"I personally end up using MATLAB quite a bit more often for various reasons.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "\"So one more organizational question. I'm curious, how many of you know MATLAB? Wow, cool, quite a lot. Okay. So as part of the — actually how many of you know Octave or have used Octave ? Oh, okay, much smaller number.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "So later this quarter, we'll use the discussion sections to talk about things like convex \n",
      "optimization, to talk a little bit about hidde n Markov models, which is a type of machine \n",
      "learning algorithm for modeling time series and a few other things, so  extensions to the \n",
      "materials that I'll be covering in the main  lectures. And attend ance at the discussion \n",
      "sections is optional, okay?  \n",
      "So that was all I had from l ogistics. Before we move on to start talking a bit about \n",
      "machine learning, let me check what questions you have. Yeah?  \n",
      "Student : [Inaudible] R or something like that?  \n",
      "Instructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \n",
      "welcome to use R, but I would strongly advi se against it, mainly because in the last \n",
      "problem set, we actually supply some code th at will run in Octave  but that would be \n",
      "somewhat painful for you to translate into R yourself. So for your other assignments, if \n",
      "you wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \n",
      "worth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \n",
      "bit more often for various reasons. Yeah?  \n",
      "Student : For the [inaudible] pr oject [inaudible]?  \n",
      "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \n",
      "groups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \n",
      "same regardless of the group size, so with  a larger group, you probably — I recommend\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learning class. I learned so much from it. There's this stuff that I learned in your \n",
      "class, and I now use every day. And it's help ed me make lots of money, and here's a \n",
      "picture of my big house.\"  \n",
      "So my friend was very excited. He said, \"W ow. That's great. I'm glad to hear this \n",
      "machine learning stuff was actually useful. So what was it that you learned? Was it \n",
      "logistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \n",
      "learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
      "and we'll actually have a short MATLAB tutori al in one of the discussion sections for \n",
      "those of you that don't know it.  \n",
      "Okay. The very last piece of logistical th ing is the discussion s ections. So discussion \n",
      "sections will be taught by the TAs, and atte ndance at discussion sections is optional, \n",
      "although they'll also be recorded and televi sed. And we'll use the discussion sections \n",
      "mainly for two things. For the next two or th ree weeks, we'll use the discussion sections \n",
      "to go over the prerequisites to this class or if some of you haven't seen probability or \n",
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn't.  \n",
      "So I guess for those of you that haven't s een MATLAB before, and I know most of you \n",
      "have, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \n",
      "plot data. And it's sort of an extremely easy to  learn tool to use for implementing a lot of \n",
      "learning algorithms.  \n",
      "And in case some of you want to work on your  own home computer or something if you \n",
      "don't have a MATLAB license, for the purposes of  this class, there's also — [inaudible] \n",
      "write that down [inaudible] MATLAB — there' s also a software package called Octave \n",
      "that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of  this class, it will work for just about \n",
      "everything.  \n",
      "So actually I, well, so yeah, just a side comment for those of you that haven't seen \n",
      "MATLAB before I guess, once a colleague of mine at a different university, not at \n",
      "Stanford, actually teaches another machine l earning course. He's taught it for many years. \n",
      "So one day, he was in his office, and an old student of his from, lik e, ten years ago came \n",
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "person's face physically attractive. There's a learning algorithm on op tical illusions, and \n",
      "so on.  \n",
      "And it goes on, so lots of fun projects. A nd take a look, then come up with your own \n",
      "ideas. But whatever you find cool and interest ing, I hope you'll be able to make machine \n",
      "learning a project out of it. Yeah, question?  \n",
      "Student : Are these gro up projects?  \n",
      "Instructor (Andrew Ng): Oh, yes, thank you.  \n",
      "Student : So how many people can be in a group?  \n",
      "Instructor (Andrew Ng): Right. So projects can be done in  groups of up to three people. \n",
      "So as part of forming study groups, later t oday as you get to know your classmates, I \n",
      "definitely also encourage you to grab two ot her people and form a group of up to three \n",
      "people for your project, okay? And just start brainstorming ideas for now amongst \n",
      "yourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \n",
      "with us.  \n",
      "Okay. So one more organizational ques tion. I'm curious, how many of you know \n",
      "MATLAB? Wow, cool, quite a lot. Okay. So as part of the — act ually how many of you \n",
      "know Octave or have used Octave ? Oh, okay, much smaller number.  \n",
      "So as part of this class, especially in the homeworks, we'll ask you to implement a few \n",
      "programs, a few machine learning algorithms as  part of the homeworks. And most of\n"
     ]
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(question, k=4)\n",
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 7, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "None\n",
      "{'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 7, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_metadata(compressed_docs))\n",
    "print(get_metadata(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine threshold score and Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(\n",
    "        search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.9}\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alli/miniconda3/envs/openai/lib/python3.11/site-packages/langchain/vectorstores/base.py:266: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compression_retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine MMR and Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alli/miniconda3/envs/openai/lib/python3.11/site-packages/langchain/chains/llm.py:278: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-text-davinci-003 in organization org-OKEaxoW73Lo9pocIXi1wDApB on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type=\"mmr\"),\n",
    ")\n",
    "\n",
    "docs = compression_retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "\"I personally end up using MATLAB quite a bit more often for various reasons.\"\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RetrievalQA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2}),\n",
    ")\n",
    "\n",
    "# qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what did they say about matlab?',\n",
       " 'result': '\\n\\nMatlab is a programming language and environment that is commonly used in data analysis, visualization, and numerical computing. It is widely used in scientific and engineering fields, including physics, engineering, and finance. It is often used to create interactive visualizations and perform complex numerical computations. It is also used to develop and test algorithms, which are mathematical procedures that can be used to solve complex problems. It is a powerful tool for data analysis and can be used to analyze large datasets, perform statistical analysis, and create complex visualizations. It is also used to develop and test algorithms, which are mathematical procedures that can be used to solve complex problems.',\n",
       " 'source_documents': [Document(page_content=\"So later this quarter, we'll use the discussion sections to talk about things like convex \\noptimization, to talk a little bit about hidde n Markov models, which is a type of machine \\nlearning algorithm for modeling time series and a few other things, so  extensions to the \\nmaterials that I'll be covering in the main  lectures. And attend ance at the discussion \\nsections is optional, okay?  \\nSo that was all I had from l ogistics. Before we move on to start talking a bit about \\nmachine learning, let me check what questions you have. Yeah?  \\nStudent : [Inaudible] R or something like that?  \\nInstructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \\nwelcome to use R, but I would strongly advi se against it, mainly because in the last \\nproblem set, we actually supply some code th at will run in Octave  but that would be \\nsomewhat painful for you to translate into R yourself. So for your other assignments, if \\nyou wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \\nworth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \\nbit more often for various reasons. Yeah?  \\nStudent : For the [inaudible] pr oject [inaudible]?  \\nInstructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \\ngroups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \\nsame regardless of the group size, so with  a larger group, you probably — I recommend\", metadata={'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       "  Document(page_content=\"turns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \\nBut in contrast, if you want to do things like to get software to fl y a helicopter or have \\nsoftware recognize handwritten digits, one very  successful approach is to use a learning \\nalgorithm and have a computer learn by its elf how to, say, recognize your handwriting. \\nAnd in fact, handwritten digit recognition, this is pretty much the only approach that \\nworks well. It uses applications that are hard to program by hand.  \\nLearning algorithms has also made I guess sign ificant inroads in what's sometimes called \\ndatabase mining. So, for example, with the growth of IT and computers, increasingly \\nmany hospitals are keeping around medical reco rds of what sort of patients, what \\nproblems they had, what their prognoses was,  what the outcome was. And taking all of \\nthese medical records, which started to be digitized only about maybe 15 years, applying \\nlearning algorithms to them can turn raw medi cal records into what I might loosely call \\nmedical knowledge in which we start to detect trends in medical practice and even start to \\nalter medical practice as a result of me dical knowledge that's derived by applying \\nlearning algorithms to the sorts of medical r ecords that hospitals have just been building \\nover the last 15, 20 years in an electronic format.  \\nTurns out that most of you probably use learning algorithms — I don't know — I think\", metadata={'page': 2, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})]}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "result = qa_chain({\"query\": question}) \n",
    "\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "So later this quarter, we'll use the discussion sections to talk about things like convex \n",
      "optimization, to talk a little bit about hidde n Markov models, which is a type of machine \n",
      "learning algorithm for modeling time series and a few other things, so  extensions to the \n",
      "materials that I'll be covering in the main  lectures. And attend ance at the discussion \n",
      "sections is optional, okay?  \n",
      "So that was all I had from l ogistics. Before we move on to start talking a bit about \n",
      "machine learning, let me check what questions you have. Yeah?  \n",
      "Student : [Inaudible] R or something like that?  \n",
      "Instructor (Andrew Ng) : Oh, yeah, let's see, right. So our policy has been that you're \n",
      "welcome to use R, but I would strongly advi se against it, mainly because in the last \n",
      "problem set, we actually supply some code th at will run in Octave  but that would be \n",
      "somewhat painful for you to translate into R yourself. So for your other assignments, if \n",
      "you wanna submit a solution in R, that's fi ne. But I think MATLAB is actually totally \n",
      "worth learning. I know R and MATLAB, and I personally end up using MATLAB quite a \n",
      "bit more often for various reasons. Yeah?  \n",
      "Student : For the [inaudible] pr oject [inaudible]?  \n",
      "Instructor (Andrew Ng) : So for the term project, you're welcome to do it in smaller \n",
      "groups of three, or you're welcome to do it by yo urself or in groups of two. Grading is the \n",
      "same regardless of the group size, so with  a larger group, you probably — I recommend\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "turns out to be extremely difficult to sit dow n and write a program to  fly a helicopter.  \n",
      "But in contrast, if you want to do things like to get software to fl y a helicopter or have \n",
      "software recognize handwritten digits, one very  successful approach is to use a learning \n",
      "algorithm and have a computer learn by its elf how to, say, recognize your handwriting. \n",
      "And in fact, handwritten digit recognition, this is pretty much the only approach that \n",
      "works well. It uses applications that are hard to program by hand.  \n",
      "Learning algorithms has also made I guess sign ificant inroads in what's sometimes called \n",
      "database mining. So, for example, with the growth of IT and computers, increasingly \n",
      "many hospitals are keeping around medical reco rds of what sort of patients, what \n",
      "problems they had, what their prognoses was,  what the outcome was. And taking all of \n",
      "these medical records, which started to be digitized only about maybe 15 years, applying \n",
      "learning algorithms to them can turn raw medi cal records into what I might loosely call \n",
      "medical knowledge in which we start to detect trends in medical practice and even start to \n",
      "alter medical practice as a result of me dical knowledge that's derived by applying \n",
      "learning algorithms to the sorts of medical r ecords that hospitals have just been building \n",
      "over the last 15, 20 years in an electronic format.  \n",
      "Turns out that most of you probably use learning algorithms — I don't know — I think\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 9, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 2, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "get_metadata(result['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The students were told that MATLAB was a good tool to use for their project, but that it was not necessary to use it for the term project. The instructor also stated that he personally used MATLAB more often than R.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result'].strip('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
